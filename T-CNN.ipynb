{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:200: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/krf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:201: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/krf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:204: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/krf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:206: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/278]\tLoss 6.91405\tAcc nan\tPrecision nan\tRecall nan\tF1 nan\n",
      "Epoch: [0][10/278]\tLoss 6.81572\tAcc 0.71168\tPrecision nan\tRecall 0.00000\tF1 nan\n",
      "Epoch: [0][20/278]\tLoss 6.58653\tAcc 0.72391\tPrecision nan\tRecall 0.00000\tF1 nan\n",
      "Epoch: [0][30/278]\tLoss 5.76707\tAcc 0.68709\tPrecision 0.32812\tRecall 0.07955\tF1 0.12805\n",
      "Epoch: [0][40/278]\tLoss 5.44820\tAcc 0.67909\tPrecision 0.32292\tRecall 0.08564\tF1 0.13537\n",
      "Epoch: [0][50/278]\tLoss 5.23110\tAcc 0.65701\tPrecision 0.30208\tRecall 0.12691\tF1 0.17874\n",
      "Epoch: [0][60/278]\tLoss 5.03595\tAcc 0.66275\tPrecision 0.29911\tRecall 0.12362\tF1 0.17493\n",
      "Epoch: [0][70/278]\tLoss 4.50258\tAcc 0.66272\tPrecision 0.30859\tRecall 0.12305\tF1 0.17595\n",
      "Epoch: [0][80/278]\tLoss 4.09323\tAcc 0.66667\tPrecision 0.31250\tRecall 0.12329\tF1 0.17682\n",
      "Epoch: [0][90/278]\tLoss 3.72702\tAcc 0.66126\tPrecision 0.29664\tRecall 0.11729\tF1 0.16811\n",
      "Epoch: [0][100/278]\tLoss 3.43316\tAcc 0.65346\tPrecision 0.27473\tRecall 0.10764\tF1 0.15468\n",
      "Epoch: [0][110/278]\tLoss 3.18632\tAcc 0.65141\tPrecision 0.27179\tRecall 0.10261\tF1 0.14898\n",
      "Epoch: [0][120/278]\tLoss 2.97624\tAcc 0.65340\tPrecision 0.27179\tRecall 0.09323\tF1 0.13883\n",
      "Epoch: [0][130/278]\tLoss 2.79686\tAcc 0.65654\tPrecision 0.27179\tRecall 0.08583\tF1 0.13046\n",
      "Epoch: [0][140/278]\tLoss 2.63617\tAcc 0.66486\tPrecision 0.27179\tRecall 0.08104\tF1 0.12485\n",
      "Epoch: [0][150/278]\tLoss 2.50284\tAcc 0.66554\tPrecision 0.27179\tRecall 0.07507\tF1 0.11765\n",
      "Epoch: [0][160/278]\tLoss 2.38520\tAcc 0.66772\tPrecision 0.27110\tRecall 0.07034\tF1 0.11170\n",
      "Epoch: [0][170/278]\tLoss 2.27788\tAcc 0.67223\tPrecision 0.27110\tRecall 0.06671\tF1 0.10707\n",
      "Epoch: [0][180/278]\tLoss 2.18454\tAcc 0.67413\tPrecision 0.27110\tRecall 0.06298\tF1 0.10222\n",
      "Epoch: [0][190/278]\tLoss 2.10124\tAcc 0.67451\tPrecision 0.26566\tRecall 0.05965\tF1 0.09743\n",
      "Epoch: [0][200/278]\tLoss 2.02755\tAcc 0.67438\tPrecision 0.25728\tRecall 0.05671\tF1 0.09294\n",
      "Epoch: [0][210/278]\tLoss 1.96057\tAcc 0.67726\tPrecision 0.25728\tRecall 0.05425\tF1 0.08960\n",
      "Epoch: [0][220/278]\tLoss 1.89886\tAcc 0.67572\tPrecision 0.25225\tRecall 0.05469\tF1 0.08989\n",
      "Epoch: [0][230/278]\tLoss 1.84313\tAcc 0.67747\tPrecision 0.25225\tRecall 0.05236\tF1 0.08672\n",
      "Epoch: [0][240/278]\tLoss 1.79368\tAcc 0.67920\tPrecision 0.25225\tRecall 0.05025\tF1 0.08380\n",
      "Epoch: [0][250/278]\tLoss 1.74776\tAcc 0.67890\tPrecision 0.25225\tRecall 0.04799\tF1 0.08063\n",
      "Epoch: [0][260/278]\tLoss 1.70406\tAcc 0.68057\tPrecision 0.25225\tRecall 0.04622\tF1 0.07813\n",
      "Epoch: [0][270/278]\tLoss 1.66663\tAcc 0.67978\tPrecision 0.26025\tRecall 0.05044\tF1 0.08450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:138: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/krf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/21]\tLoss 0.40487\tAcc 1.00000\tPrecision nan\tRecall nan\tF1 nan\n",
      "Test: [10/21]\tLoss 0.42562\tAcc 1.00000\tPrecision nan\tRecall nan\tF1 nan\n",
      "Test: [20/21]\tLoss 0.65343\tAcc 0.60301\tPrecision nan\tRecall 0.00000\tF1 nan\n",
      " * Acc 0.60301 F1 nan\n",
      "Epoch: [1][0/278]\tLoss 1.63756\tAcc 0.68054\tPrecision 0.26025\tRecall 0.04903\tF1 0.08252\n",
      "Epoch: [1][10/278]\tLoss 1.60109\tAcc 0.68166\tPrecision 0.26025\tRecall 0.04735\tF1 0.08013\n",
      "Epoch: [1][20/278]\tLoss 1.56796\tAcc 0.68386\tPrecision 0.26025\tRecall 0.04596\tF1 0.07813\n",
      "Epoch: [1][30/278]\tLoss 1.53751\tAcc 0.68439\tPrecision 0.26025\tRecall 0.04442\tF1 0.07589\n",
      "Epoch: [1][40/278]\tLoss 1.50819\tAcc 0.68547\tPrecision 0.26025\tRecall 0.04307\tF1 0.07390\n",
      "Epoch: [1][50/278]\tLoss 1.47997\tAcc 0.68582\tPrecision 0.26025\tRecall 0.04169\tF1 0.07187\n",
      "Epoch: [1][60/278]\tLoss 1.45537\tAcc 0.68717\tPrecision 0.26653\tRecall 0.04245\tF1 0.07324\n",
      "Epoch: [1][70/278]\tLoss 1.43166\tAcc 0.68538\tPrecision 0.28253\tRecall 0.05105\tF1 0.08648\n",
      "Epoch: [1][80/278]\tLoss 1.40853\tAcc 0.68535\tPrecision 0.28381\tRecall 0.05108\tF1 0.08658\n",
      "Epoch: [1][90/278]\tLoss 1.38727\tAcc 0.68575\tPrecision 0.29276\tRecall 0.05188\tF1 0.08814\n",
      "Epoch: [1][100/278]\tLoss 1.36579\tAcc 0.68621\tPrecision 0.29690\tRecall 0.05157\tF1 0.08788\n",
      "Epoch: [1][110/278]\tLoss 1.34528\tAcc 0.68714\tPrecision 0.29690\tRecall 0.05030\tF1 0.08603\n",
      "Epoch: [1][120/278]\tLoss 1.32600\tAcc 0.68707\tPrecision 0.30032\tRecall 0.04970\tF1 0.08529\n",
      "Epoch: [1][130/278]\tLoss 1.30645\tAcc 0.68792\tPrecision 0.30032\tRecall 0.04854\tF1 0.08358\n",
      "Epoch: [1][140/278]\tLoss 1.28891\tAcc 0.68791\tPrecision 0.30225\tRecall 0.04807\tF1 0.08295\n",
      "Epoch: [1][150/278]\tLoss 1.27155\tAcc 0.68886\tPrecision 0.30952\tRecall 0.04870\tF1 0.08416\n",
      "Epoch: [1][160/278]\tLoss 1.25568\tAcc 0.68926\tPrecision 0.31860\tRecall 0.05098\tF1 0.08789\n",
      "Epoch: [1][170/278]\tLoss 1.24143\tAcc 0.68950\tPrecision 0.33428\tRecall 0.05619\tF1 0.09621\n",
      "Epoch: [1][180/278]\tLoss 1.22590\tAcc 0.68973\tPrecision 0.33568\tRecall 0.05539\tF1 0.09509\n",
      "Epoch: [1][190/278]\tLoss 1.21236\tAcc 0.69008\tPrecision 0.34794\tRecall 0.06153\tF1 0.10457\n",
      "Epoch: [1][200/278]\tLoss 1.19880\tAcc 0.69049\tPrecision 0.35741\tRecall 0.06278\tF1 0.10680\n",
      "Epoch: [1][210/278]\tLoss 1.18489\tAcc 0.69081\tPrecision 0.36386\tRecall 0.06313\tF1 0.10759\n",
      "Epoch: [1][220/278]\tLoss 1.17086\tAcc 0.69238\tPrecision 0.37192\tRecall 0.06457\tF1 0.11004\n",
      "Epoch: [1][230/278]\tLoss 1.15782\tAcc 0.69370\tPrecision 0.38725\tRecall 0.06875\tF1 0.11677\n",
      "Epoch: [1][240/278]\tLoss 1.14511\tAcc 0.69510\tPrecision 0.39464\tRecall 0.06981\tF1 0.11864\n",
      "Epoch: [1][250/278]\tLoss 1.13494\tAcc 0.69489\tPrecision 0.41103\tRecall 0.07952\tF1 0.13327\n",
      "Epoch: [1][260/278]\tLoss 1.12291\tAcc 0.69627\tPrecision 0.41590\tRecall 0.08084\tF1 0.13537\n",
      "Epoch: [1][270/278]\tLoss 1.11171\tAcc 0.69731\tPrecision 0.42016\tRecall 0.08205\tF1 0.13729\n",
      "Test: [0/21]\tLoss 0.64037\tAcc 0.62123\tPrecision nan\tRecall 0.00000\tF1 nan\n",
      "Test: [10/21]\tLoss 0.50959\tAcc 0.74041\tPrecision nan\tRecall 0.00000\tF1 nan\n",
      "Test: [20/21]\tLoss 0.63381\tAcc 0.63534\tPrecision 1.00000\tRecall 0.08144\tF1 0.15061\n",
      " * Acc 0.63534 F1 0.15061\n",
      "Epoch: [2][0/278]\tLoss 1.10295\tAcc 0.69858\tPrecision 0.42646\tRecall 0.08317\tF1 0.13920\n",
      "Epoch: [2][10/278]\tLoss 1.09251\tAcc 0.69999\tPrecision 0.43673\tRecall 0.08692\tF1 0.14498\n",
      "Epoch: [2][20/278]\tLoss 1.08327\tAcc 0.70021\tPrecision 0.44704\tRecall 0.09243\tF1 0.15318\n",
      "Epoch: [2][30/278]\tLoss 1.07321\tAcc 0.70138\tPrecision 0.45423\tRecall 0.09516\tF1 0.15735\n",
      "Epoch: [2][40/278]\tLoss 1.06434\tAcc 0.70225\tPrecision 0.46012\tRecall 0.09849\tF1 0.16225\n",
      "Epoch: [2][50/278]\tLoss 1.05647\tAcc 0.70253\tPrecision 0.46508\tRecall 0.10352\tF1 0.16934\n",
      "Epoch: [2][60/278]\tLoss 1.04867\tAcc 0.70304\tPrecision 0.47364\tRecall 0.10913\tF1 0.17738\n",
      "Epoch: [2][70/278]\tLoss 1.04048\tAcc 0.70410\tPrecision 0.48078\tRecall 0.11324\tF1 0.18330\n",
      "Epoch: [2][80/278]\tLoss 1.03262\tAcc 0.70398\tPrecision 0.48297\tRecall 0.11906\tF1 0.19103\n",
      "Epoch: [2][90/278]\tLoss 1.02637\tAcc 0.70436\tPrecision 0.48698\tRecall 0.12360\tF1 0.19715\n",
      "Epoch: [2][100/278]\tLoss 1.01897\tAcc 0.70501\tPrecision 0.49246\tRecall 0.12750\tF1 0.20256\n",
      "Epoch: [2][110/278]\tLoss 1.01315\tAcc 0.70460\tPrecision 0.48854\tRecall 0.12985\tF1 0.20517\n",
      "Epoch: [2][120/278]\tLoss 1.00642\tAcc 0.70491\tPrecision 0.49329\tRecall 0.13342\tF1 0.21003\n",
      "Epoch: [2][130/278]\tLoss 0.99878\tAcc 0.70561\tPrecision 0.49595\tRecall 0.13330\tF1 0.21013\n",
      "Epoch: [2][140/278]\tLoss 0.99157\tAcc 0.70661\tPrecision 0.49742\tRecall 0.13342\tF1 0.21040\n",
      "Epoch: [2][150/278]\tLoss 0.98528\tAcc 0.70687\tPrecision 0.49665\tRecall 0.13503\tF1 0.21233\n",
      "Epoch: [2][160/278]\tLoss 0.97845\tAcc 0.70765\tPrecision 0.50138\tRecall 0.13615\tF1 0.21414\n",
      "Epoch: [2][170/278]\tLoss 0.97170\tAcc 0.70845\tPrecision 0.50783\tRecall 0.13858\tF1 0.21774\n",
      "Epoch: [2][180/278]\tLoss 0.96540\tAcc 0.70923\tPrecision 0.51682\tRecall 0.14261\tF1 0.22354\n",
      "Epoch: [2][190/278]\tLoss 0.95918\tAcc 0.70957\tPrecision 0.51928\tRecall 0.14451\tF1 0.22610\n",
      "Epoch: [2][200/278]\tLoss 0.95277\tAcc 0.71044\tPrecision 0.52282\tRecall 0.14570\tF1 0.22790\n",
      "Epoch: [2][210/278]\tLoss 0.94622\tAcc 0.71124\tPrecision 0.52558\tRecall 0.14635\tF1 0.22895\n",
      "Epoch: [2][220/278]\tLoss 0.93997\tAcc 0.71239\tPrecision 0.53255\tRecall 0.14994\tF1 0.23400\n",
      "Epoch: [2][230/278]\tLoss 0.93474\tAcc 0.71295\tPrecision 0.53529\tRecall 0.15374\tF1 0.23888\n",
      "Epoch: [2][240/278]\tLoss 0.93167\tAcc 0.71259\tPrecision 0.53285\tRecall 0.15792\tF1 0.24363\n",
      "Epoch: [2][250/278]\tLoss 0.92755\tAcc 0.71259\tPrecision 0.53249\tRecall 0.16187\tF1 0.24827\n",
      "Epoch: [2][260/278]\tLoss 0.92382\tAcc 0.71186\tPrecision 0.52816\tRecall 0.16571\tF1 0.25227\n",
      "Epoch: [2][270/278]\tLoss 0.91961\tAcc 0.71171\tPrecision 0.52697\tRecall 0.16923\tF1 0.25619\n",
      "Test: [0/21]\tLoss 0.63041\tAcc 0.64391\tPrecision 1.00000\tRecall 0.08144\tF1 0.15061\n",
      "Test: [10/21]\tLoss 0.60099\tAcc 0.71165\tPrecision 1.00000\tRecall 0.08144\tF1 0.15061\n",
      "Test: [20/21]\tLoss 0.64985\tAcc 0.62456\tPrecision 1.00000\tRecall 0.05429\tF1 0.10299\n",
      " * Acc 0.62456 F1 0.10299\n",
      "Epoch: [3][0/278]\tLoss 0.91680\tAcc 0.71178\tPrecision 0.52583\tRecall 0.16835\tF1 0.25505\n",
      "Epoch: [3][10/278]\tLoss 0.91474\tAcc 0.70979\tPrecision 0.51562\tRecall 0.16930\tF1 0.25491\n",
      "Epoch: [3][20/278]\tLoss 0.91097\tAcc 0.71015\tPrecision 0.51703\tRecall 0.17099\tF1 0.25698\n",
      "Epoch: [3][30/278]\tLoss 0.90718\tAcc 0.70974\tPrecision 0.51565\tRecall 0.17310\tF1 0.25919\n",
      "Epoch: [3][40/278]\tLoss 0.90333\tAcc 0.71017\tPrecision 0.51734\tRecall 0.17506\tF1 0.26160\n",
      "Epoch: [3][50/278]\tLoss 0.89894\tAcc 0.71066\tPrecision 0.51974\tRecall 0.17658\tF1 0.26360\n",
      "Epoch: [3][60/278]\tLoss 0.89412\tAcc 0.71155\tPrecision 0.52238\tRecall 0.17734\tF1 0.26478\n",
      "Epoch: [3][70/278]\tLoss 0.88957\tAcc 0.71212\tPrecision 0.52376\tRecall 0.17756\tF1 0.26522\n",
      "Epoch: [3][80/278]\tLoss 0.88524\tAcc 0.71284\tPrecision 0.52733\tRecall 0.17971\tF1 0.26806\n",
      "Epoch: [3][90/278]\tLoss 0.88130\tAcc 0.71335\tPrecision 0.52921\tRecall 0.18062\tF1 0.26932\n",
      "Epoch: [3][100/278]\tLoss 0.87867\tAcc 0.71297\tPrecision 0.52781\tRecall 0.18382\tF1 0.27267\n",
      "Epoch: [3][110/278]\tLoss 0.87505\tAcc 0.71349\tPrecision 0.52780\tRecall 0.18546\tF1 0.27448\n",
      "Epoch: [3][120/278]\tLoss 0.87107\tAcc 0.71404\tPrecision 0.53040\tRecall 0.18820\tF1 0.27782\n",
      "Epoch: [3][130/278]\tLoss 0.86735\tAcc 0.71438\tPrecision 0.52982\tRecall 0.18898\tF1 0.27858\n",
      "Epoch: [3][140/278]\tLoss 0.86370\tAcc 0.71469\tPrecision 0.53249\tRecall 0.18952\tF1 0.27954\n",
      "Epoch: [3][150/278]\tLoss 0.86014\tAcc 0.71511\tPrecision 0.53575\tRecall 0.19175\tF1 0.28242\n",
      "Epoch: [3][160/278]\tLoss 0.85670\tAcc 0.71574\tPrecision 0.53998\tRecall 0.19488\tF1 0.28639\n",
      "Epoch: [3][170/278]\tLoss 0.85334\tAcc 0.71609\tPrecision 0.54245\tRecall 0.19734\tF1 0.28940\n",
      "Epoch: [3][180/278]\tLoss 0.85012\tAcc 0.71661\tPrecision 0.54514\tRecall 0.19983\tF1 0.29246\n",
      "Epoch: [3][190/278]\tLoss 0.84681\tAcc 0.71684\tPrecision 0.54735\tRecall 0.20244\tF1 0.29556\n",
      "Epoch: [3][200/278]\tLoss 0.84348\tAcc 0.71750\tPrecision 0.54996\tRecall 0.20403\tF1 0.29764\n",
      "Epoch: [3][210/278]\tLoss 0.84003\tAcc 0.71805\tPrecision 0.55410\tRecall 0.20707\tF1 0.30147\n",
      "Epoch: [3][220/278]\tLoss 0.83561\tAcc 0.71913\tPrecision 0.55652\tRecall 0.20803\tF1 0.30285\n",
      "Epoch: [3][230/278]\tLoss 0.83270\tAcc 0.71903\tPrecision 0.55550\tRecall 0.20902\tF1 0.30374\n",
      "Epoch: [3][240/278]\tLoss 0.82947\tAcc 0.71961\tPrecision 0.55684\tRecall 0.21061\tF1 0.30563\n",
      "Epoch: [3][250/278]\tLoss 0.82739\tAcc 0.71949\tPrecision 0.55635\tRecall 0.21354\tF1 0.30862\n",
      "Epoch: [3][260/278]\tLoss 0.82410\tAcc 0.72034\tPrecision 0.55990\tRecall 0.21541\tF1 0.31112\n",
      "Epoch: [3][270/278]\tLoss 0.82085\tAcc 0.72078\tPrecision 0.56107\tRecall 0.21785\tF1 0.31384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/21]\tLoss 0.64396\tAcc 0.63049\tPrecision 1.00000\tRecall 0.05429\tF1 0.10299\n",
      "Test: [10/21]\tLoss 0.58772\tAcc 0.67916\tPrecision 0.91489\tRecall 0.05429\tF1 0.10250\n",
      "Test: [20/21]\tLoss 0.64576\tAcc 0.65075\tPrecision 0.87135\tRecall 0.14110\tF1 0.24287\n",
      " * Acc 0.65075 F1 0.24287\n",
      "Epoch: [4][0/278]\tLoss 0.81834\tAcc 0.72122\tPrecision 0.56269\tRecall 0.21915\tF1 0.31544\n",
      "Epoch: [4][10/278]\tLoss 0.81550\tAcc 0.72162\tPrecision 0.56334\tRecall 0.22002\tF1 0.31645\n",
      "Epoch: [4][20/278]\tLoss 0.81220\tAcc 0.72223\tPrecision 0.56504\tRecall 0.22097\tF1 0.31770\n",
      "Epoch: [4][30/278]\tLoss 0.80910\tAcc 0.72294\tPrecision 0.56860\tRecall 0.22356\tF1 0.32094\n",
      "Epoch: [4][40/278]\tLoss 0.80600\tAcc 0.72358\tPrecision 0.57150\tRecall 0.22554\tF1 0.32344\n",
      "Epoch: [4][50/278]\tLoss 0.80292\tAcc 0.72427\tPrecision 0.57392\tRecall 0.22759\tF1 0.32593\n",
      "Epoch: [4][60/278]\tLoss 0.79992\tAcc 0.72487\tPrecision 0.57537\tRecall 0.22865\tF1 0.32726\n",
      "Epoch: [4][70/278]\tLoss 0.79733\tAcc 0.72508\tPrecision 0.57695\tRecall 0.23092\tF1 0.32982\n",
      "Epoch: [4][80/278]\tLoss 0.79450\tAcc 0.72563\tPrecision 0.57793\tRecall 0.23265\tF1 0.33175\n",
      "Epoch: [4][90/278]\tLoss 0.79227\tAcc 0.72601\tPrecision 0.57964\tRecall 0.23595\tF1 0.33538\n",
      "Epoch: [4][100/278]\tLoss 0.79037\tAcc 0.72608\tPrecision 0.57777\tRecall 0.23688\tF1 0.33601\n",
      "Epoch: [4][110/278]\tLoss 0.78869\tAcc 0.72584\tPrecision 0.57579\tRecall 0.23800\tF1 0.33678\n",
      "Epoch: [4][120/278]\tLoss 0.78601\tAcc 0.72630\tPrecision 0.57696\tRecall 0.23985\tF1 0.33884\n",
      "Epoch: [4][130/278]\tLoss 0.78384\tAcc 0.72649\tPrecision 0.57760\tRecall 0.24220\tF1 0.34129\n",
      "Epoch: [4][140/278]\tLoss 0.78258\tAcc 0.72605\tPrecision 0.57551\tRecall 0.24423\tF1 0.34293\n",
      "Epoch: [4][150/278]\tLoss 0.78048\tAcc 0.72626\tPrecision 0.57629\tRecall 0.24523\tF1 0.34406\n",
      "Epoch: [4][160/278]\tLoss 0.77899\tAcc 0.72589\tPrecision 0.57406\tRecall 0.24674\tF1 0.34514\n",
      "Epoch: [4][170/278]\tLoss 0.77732\tAcc 0.72573\tPrecision 0.57256\tRecall 0.24766\tF1 0.34576\n",
      "Epoch: [4][180/278]\tLoss 0.77523\tAcc 0.72602\tPrecision 0.57416\tRecall 0.24899\tF1 0.34734\n",
      "Epoch: [4][190/278]\tLoss 0.77288\tAcc 0.72647\tPrecision 0.57521\tRecall 0.25014\tF1 0.34866\n",
      "Epoch: [4][200/278]\tLoss 0.77119\tAcc 0.72641\tPrecision 0.57492\tRecall 0.25149\tF1 0.34991\n",
      "Epoch: [4][210/278]\tLoss 0.76908\tAcc 0.72663\tPrecision 0.57618\tRecall 0.25344\tF1 0.35203\n",
      "Epoch: [4][220/278]\tLoss 0.76726\tAcc 0.72702\tPrecision 0.57740\tRecall 0.25580\tF1 0.35453\n",
      "Epoch: [4][230/278]\tLoss 0.76555\tAcc 0.72719\tPrecision 0.57768\tRecall 0.25752\tF1 0.35624\n",
      "Epoch: [4][240/278]\tLoss 0.76340\tAcc 0.72736\tPrecision 0.57744\tRecall 0.25933\tF1 0.35791\n",
      "Epoch: [4][250/278]\tLoss 0.76083\tAcc 0.72780\tPrecision 0.57818\tRecall 0.25933\tF1 0.35806\n",
      "Epoch: [4][260/278]\tLoss 0.75901\tAcc 0.72806\tPrecision 0.57944\tRecall 0.26167\tF1 0.36052\n",
      "Epoch: [4][270/278]\tLoss 0.75696\tAcc 0.72858\tPrecision 0.58130\tRecall 0.26343\tF1 0.36256\n",
      "Test: [0/21]\tLoss 0.64510\tAcc 0.65119\tPrecision 0.82320\tRecall 0.14110\tF1 0.24091\n",
      "Test: [10/21]\tLoss 0.62693\tAcc 0.66833\tPrecision 0.61826\tRecall 0.14110\tF1 0.22976\n",
      "Test: [20/21]\tLoss 0.63407\tAcc 0.66256\tPrecision 0.70886\tRecall 0.25455\tF1 0.37458\n",
      " * Acc 0.66256 F1 0.37458\n",
      "Epoch: [5][0/278]\tLoss 0.75557\tAcc 0.72893\tPrecision 0.58243\tRecall 0.26509\tF1 0.36435\n",
      "Epoch: [5][10/278]\tLoss 0.75396\tAcc 0.72895\tPrecision 0.58188\tRecall 0.26664\tF1 0.36570\n",
      "Epoch: [5][20/278]\tLoss 0.75249\tAcc 0.72917\tPrecision 0.58156\tRecall 0.26796\tF1 0.36687\n",
      "Epoch: [5][30/278]\tLoss 0.75065\tAcc 0.72916\tPrecision 0.58193\tRecall 0.26863\tF1 0.36758\n",
      "Epoch: [5][40/278]\tLoss 0.74920\tAcc 0.72920\tPrecision 0.58264\tRecall 0.27105\tF1 0.36998\n",
      "Epoch: [5][50/278]\tLoss 0.74760\tAcc 0.72932\tPrecision 0.58377\tRecall 0.27321\tF1 0.37222\n",
      "Epoch: [5][60/278]\tLoss 0.74619\tAcc 0.72981\tPrecision 0.58556\tRecall 0.27539\tF1 0.37461\n",
      "Epoch: [5][70/278]\tLoss 0.74433\tAcc 0.73022\tPrecision 0.58585\tRecall 0.27647\tF1 0.37566\n",
      "Epoch: [5][80/278]\tLoss 0.74234\tAcc 0.73055\tPrecision 0.58605\tRecall 0.27700\tF1 0.37619\n",
      "Epoch: [5][90/278]\tLoss 0.74113\tAcc 0.73045\tPrecision 0.58591\tRecall 0.27872\tF1 0.37775\n",
      "Epoch: [5][100/278]\tLoss 0.73943\tAcc 0.73077\tPrecision 0.58606\tRecall 0.27957\tF1 0.37856\n",
      "Epoch: [5][110/278]\tLoss 0.73790\tAcc 0.73109\tPrecision 0.58665\tRecall 0.27985\tF1 0.37894\n",
      "Epoch: [5][120/278]\tLoss 0.73613\tAcc 0.73159\tPrecision 0.58772\tRecall 0.28053\tF1 0.37978\n",
      "Epoch: [5][130/278]\tLoss 0.73434\tAcc 0.73204\tPrecision 0.58959\tRecall 0.28193\tF1 0.38146\n",
      "Epoch: [5][140/278]\tLoss 0.73300\tAcc 0.73226\tPrecision 0.58949\tRecall 0.28303\tF1 0.38244\n",
      "Epoch: [5][150/278]\tLoss 0.73142\tAcc 0.73253\tPrecision 0.58985\tRecall 0.28401\tF1 0.38341\n",
      "Epoch: [5][160/278]\tLoss 0.72956\tAcc 0.73311\tPrecision 0.59140\tRecall 0.28493\tF1 0.38457\n",
      "Epoch: [5][170/278]\tLoss 0.72789\tAcc 0.73358\tPrecision 0.59285\tRecall 0.28657\tF1 0.38637\n",
      "Epoch: [5][180/278]\tLoss 0.72632\tAcc 0.73385\tPrecision 0.59409\tRecall 0.28884\tF1 0.38870\n",
      "Epoch: [5][190/278]\tLoss 0.72456\tAcc 0.73431\tPrecision 0.59466\tRecall 0.28964\tF1 0.38955\n",
      "Epoch: [5][200/278]\tLoss 0.72309\tAcc 0.73476\tPrecision 0.59684\tRecall 0.29182\tF1 0.39198\n",
      "Epoch: [5][210/278]\tLoss 0.72187\tAcc 0.73491\tPrecision 0.59733\tRecall 0.29244\tF1 0.39265\n",
      "Epoch: [5][220/278]\tLoss 0.72033\tAcc 0.73501\tPrecision 0.59690\tRecall 0.29399\tF1 0.39395\n",
      "Epoch: [5][230/278]\tLoss 0.71927\tAcc 0.73506\tPrecision 0.59694\tRecall 0.29544\tF1 0.39525\n",
      "Epoch: [5][240/278]\tLoss 0.71785\tAcc 0.73536\tPrecision 0.59784\tRecall 0.29708\tF1 0.39692\n",
      "Epoch: [5][250/278]\tLoss 0.71642\tAcc 0.73568\tPrecision 0.59867\tRecall 0.29902\tF1 0.39884\n",
      "Epoch: [5][260/278]\tLoss 0.71504\tAcc 0.73609\tPrecision 0.59946\tRecall 0.30023\tF1 0.40009\n",
      "Epoch: [5][270/278]\tLoss 0.71365\tAcc 0.73636\tPrecision 0.59959\tRecall 0.30117\tF1 0.40094\n",
      "Test: [0/21]\tLoss 0.62873\tAcc 0.66577\tPrecision 0.70886\tRecall 0.25455\tF1 0.37458\n",
      "Test: [10/21]\tLoss 0.57878\tAcc 0.69486\tPrecision 0.70886\tRecall 0.25455\tF1 0.37458\n",
      "Test: [20/21]\tLoss 0.68350\tAcc 0.66416\tPrecision 0.73462\tRecall 0.24116\tF1 0.36312\n",
      " * Acc 0.66416 F1 0.36312\n",
      "Epoch: [6][0/278]\tLoss 0.71280\tAcc 0.73634\tPrecision 0.59941\tRecall 0.30190\tF1 0.40155\n",
      "Epoch: [6][10/278]\tLoss 0.71187\tAcc 0.73644\tPrecision 0.59899\tRecall 0.30284\tF1 0.40229\n",
      "Epoch: [6][20/278]\tLoss 0.71118\tAcc 0.73625\tPrecision 0.59744\tRecall 0.30449\tF1 0.40339\n",
      "Epoch: [6][30/278]\tLoss 0.70976\tAcc 0.73649\tPrecision 0.59833\tRecall 0.30585\tF1 0.40478\n",
      "Epoch: [6][40/278]\tLoss 0.70885\tAcc 0.73657\tPrecision 0.59866\tRecall 0.30788\tF1 0.40664\n",
      "Epoch: [6][50/278]\tLoss 0.70800\tAcc 0.73660\tPrecision 0.59807\tRecall 0.30902\tF1 0.40749\n",
      "Epoch: [6][60/278]\tLoss 0.70709\tAcc 0.73673\tPrecision 0.59888\tRecall 0.30950\tF1 0.40810\n",
      "Epoch: [6][70/278]\tLoss 0.70579\tAcc 0.73704\tPrecision 0.59943\tRecall 0.30996\tF1 0.40862\n",
      "Epoch: [6][80/278]\tLoss 0.70493\tAcc 0.73702\tPrecision 0.59920\tRecall 0.31109\tF1 0.40956\n",
      "Epoch: [6][90/278]\tLoss 0.70349\tAcc 0.73744\tPrecision 0.59972\tRecall 0.31187\tF1 0.41035\n",
      "Epoch: [6][100/278]\tLoss 0.70223\tAcc 0.73784\tPrecision 0.60102\tRecall 0.31335\tF1 0.41193\n",
      "Epoch: [6][110/278]\tLoss 0.70083\tAcc 0.73819\tPrecision 0.60184\tRecall 0.31434\tF1 0.41298\n",
      "Epoch: [6][120/278]\tLoss 0.69967\tAcc 0.73857\tPrecision 0.60274\tRecall 0.31544\tF1 0.41414\n",
      "Epoch: [6][130/278]\tLoss 0.69869\tAcc 0.73857\tPrecision 0.60251\tRecall 0.31679\tF1 0.41525\n",
      "Epoch: [6][140/278]\tLoss 0.69809\tAcc 0.73841\tPrecision 0.60199\tRecall 0.31778\tF1 0.41597\n",
      "Epoch: [6][150/278]\tLoss 0.69711\tAcc 0.73869\tPrecision 0.60280\tRecall 0.31845\tF1 0.41674\n",
      "Epoch: [6][160/278]\tLoss 0.69568\tAcc 0.73891\tPrecision 0.60375\tRecall 0.31926\tF1 0.41766\n",
      "Epoch: [6][170/278]\tLoss 0.69423\tAcc 0.73936\tPrecision 0.60471\tRecall 0.32042\tF1 0.41888\n",
      "Epoch: [6][180/278]\tLoss 0.69321\tAcc 0.73949\tPrecision 0.60484\tRecall 0.32093\tF1 0.41935\n",
      "Epoch: [6][190/278]\tLoss 0.69220\tAcc 0.73948\tPrecision 0.60436\tRecall 0.32176\tF1 0.41994\n",
      "Epoch: [6][200/278]\tLoss 0.69091\tAcc 0.73995\tPrecision 0.60582\tRecall 0.32348\tF1 0.42176\n",
      "Epoch: [6][210/278]\tLoss 0.68979\tAcc 0.74019\tPrecision 0.60615\tRecall 0.32399\tF1 0.42227\n",
      "Epoch: [6][220/278]\tLoss 0.68865\tAcc 0.74056\tPrecision 0.60731\tRecall 0.32509\tF1 0.42349\n",
      "Epoch: [6][230/278]\tLoss 0.68838\tAcc 0.74034\tPrecision 0.60602\tRecall 0.32630\tF1 0.42420\n",
      "Epoch: [6][240/278]\tLoss 0.68804\tAcc 0.74008\tPrecision 0.60493\tRecall 0.32783\tF1 0.42522\n",
      "Epoch: [6][250/278]\tLoss 0.68756\tAcc 0.74000\tPrecision 0.60442\tRecall 0.32870\tF1 0.42582\n",
      "Epoch: [6][260/278]\tLoss 0.68639\tAcc 0.74025\tPrecision 0.60454\tRecall 0.32899\tF1 0.42610\n",
      "Epoch: [6][270/278]\tLoss 0.68538\tAcc 0.74049\tPrecision 0.60509\tRecall 0.32901\tF1 0.42626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/21]\tLoss 0.67853\tAcc 0.66683\tPrecision 0.73462\tRecall 0.24116\tF1 0.36312\n",
      "Test: [10/21]\tLoss 0.63269\tAcc 0.69139\tPrecision 0.73462\tRecall 0.24116\tF1 0.36312\n",
      "Test: [20/21]\tLoss 0.70729\tAcc 0.66208\tPrecision 0.74955\tRecall 0.22348\tF1 0.34431\n",
      " * Acc 0.66208 F1 0.34431\n",
      "Epoch: [7][0/278]\tLoss 0.68430\tAcc 0.74080\tPrecision 0.60578\tRecall 0.32951\tF1 0.42684\n",
      "Epoch: [7][10/278]\tLoss 0.68395\tAcc 0.74038\tPrecision 0.60406\tRecall 0.32974\tF1 0.42661\n",
      "Epoch: [7][20/278]\tLoss 0.68309\tAcc 0.74057\tPrecision 0.60459\tRecall 0.33087\tF1 0.42768\n",
      "Epoch: [7][30/278]\tLoss 0.68214\tAcc 0.74086\tPrecision 0.60587\tRecall 0.33243\tF1 0.42931\n",
      "Epoch: [7][40/278]\tLoss 0.68120\tAcc 0.74097\tPrecision 0.60587\tRecall 0.33312\tF1 0.42988\n",
      "Epoch: [7][50/278]\tLoss 0.68027\tAcc 0.74112\tPrecision 0.60645\tRecall 0.33396\tF1 0.43072\n",
      "Epoch: [7][60/278]\tLoss 0.67920\tAcc 0.74134\tPrecision 0.60699\tRecall 0.33440\tF1 0.43123\n",
      "Epoch: [7][70/278]\tLoss 0.67840\tAcc 0.74154\tPrecision 0.60726\tRecall 0.33499\tF1 0.43179\n",
      "Epoch: [7][80/278]\tLoss 0.67729\tAcc 0.74181\tPrecision 0.60776\tRecall 0.33532\tF1 0.43219\n",
      "Epoch: [7][90/278]\tLoss 0.67655\tAcc 0.74207\tPrecision 0.60859\tRecall 0.33673\tF1 0.43356\n",
      "Epoch: [7][100/278]\tLoss 0.67545\tAcc 0.74233\tPrecision 0.60917\tRecall 0.33756\tF1 0.43441\n",
      "Epoch: [7][110/278]\tLoss 0.67426\tAcc 0.74266\tPrecision 0.60986\tRecall 0.33806\tF1 0.43499\n",
      "Epoch: [7][120/278]\tLoss 0.67342\tAcc 0.74305\tPrecision 0.61090\tRecall 0.33897\tF1 0.43601\n",
      "Epoch: [7][130/278]\tLoss 0.67241\tAcc 0.74350\tPrecision 0.61170\tRecall 0.33980\tF1 0.43690\n",
      "Epoch: [7][140/278]\tLoss 0.67137\tAcc 0.74377\tPrecision 0.61259\tRecall 0.34066\tF1 0.43784\n",
      "Epoch: [7][150/278]\tLoss 0.67084\tAcc 0.74364\tPrecision 0.61197\tRecall 0.34146\tF1 0.43834\n",
      "Epoch: [7][160/278]\tLoss 0.67012\tAcc 0.74368\tPrecision 0.61135\tRecall 0.34188\tF1 0.43853\n",
      "Epoch: [7][170/278]\tLoss 0.66932\tAcc 0.74368\tPrecision 0.61101\tRecall 0.34265\tF1 0.43907\n",
      "Epoch: [7][180/278]\tLoss 0.66833\tAcc 0.74387\tPrecision 0.61176\tRecall 0.34356\tF1 0.44001\n",
      "Epoch: [7][190/278]\tLoss 0.66750\tAcc 0.74411\tPrecision 0.61262\tRecall 0.34434\tF1 0.44087\n",
      "Epoch: [7][200/278]\tLoss 0.66669\tAcc 0.74427\tPrecision 0.61281\tRecall 0.34489\tF1 0.44137\n",
      "Epoch: [7][210/278]\tLoss 0.66581\tAcc 0.74442\tPrecision 0.61313\tRecall 0.34582\tF1 0.44222\n",
      "Epoch: [7][220/278]\tLoss 0.66513\tAcc 0.74439\tPrecision 0.61324\tRecall 0.34655\tF1 0.44284\n",
      "Epoch: [7][230/278]\tLoss 0.66417\tAcc 0.74459\tPrecision 0.61382\tRecall 0.34743\tF1 0.44371\n",
      "Epoch: [7][240/278]\tLoss 0.66315\tAcc 0.74495\tPrecision 0.61472\tRecall 0.34847\tF1 0.44480\n",
      "Epoch: [7][250/278]\tLoss 0.66221\tAcc 0.74514\tPrecision 0.61513\tRecall 0.34880\tF1 0.44517\n",
      "Epoch: [7][260/278]\tLoss 0.66152\tAcc 0.74512\tPrecision 0.61416\tRecall 0.34990\tF1 0.44581\n",
      "Epoch: [7][270/278]\tLoss 0.66056\tAcc 0.74530\tPrecision 0.61438\tRecall 0.35055\tF1 0.44640\n",
      "Test: [0/21]\tLoss 0.70501\tAcc 0.66354\tPrecision 0.74414\tRecall 0.22348\tF1 0.34374\n",
      "Test: [10/21]\tLoss 0.67714\tAcc 0.67965\tPrecision 0.70962\tRecall 0.22348\tF1 0.33992\n",
      "Test: [20/21]\tLoss 0.69679\tAcc 0.66823\tPrecision 0.72739\tRecall 0.26278\tF1 0.38609\n",
      " * Acc 0.66823 F1 0.38609\n",
      "Epoch: [8][0/278]\tLoss 0.65995\tAcc 0.74536\tPrecision 0.61452\tRecall 0.35124\tF1 0.44699\n",
      "Epoch: [8][10/278]\tLoss 0.65952\tAcc 0.74541\tPrecision 0.61382\tRecall 0.35203\tF1 0.44745\n",
      "Epoch: [8][20/278]\tLoss 0.65905\tAcc 0.74542\tPrecision 0.61341\tRecall 0.35271\tF1 0.44789\n",
      "Epoch: [8][30/278]\tLoss 0.65817\tAcc 0.74562\tPrecision 0.61405\tRecall 0.35319\tF1 0.44845\n",
      "Epoch: [8][40/278]\tLoss 0.65752\tAcc 0.74576\tPrecision 0.61414\tRecall 0.35399\tF1 0.44911\n",
      "Epoch: [8][50/278]\tLoss 0.65691\tAcc 0.74574\tPrecision 0.61432\tRecall 0.35512\tF1 0.45007\n",
      "Epoch: [8][60/278]\tLoss 0.65636\tAcc 0.74569\tPrecision 0.61401\tRecall 0.35560\tF1 0.45037\n",
      "Epoch: [8][70/278]\tLoss 0.65560\tAcc 0.74587\tPrecision 0.61454\tRecall 0.35647\tF1 0.45122\n",
      "Epoch: [8][80/278]\tLoss 0.65464\tAcc 0.74616\tPrecision 0.61532\tRecall 0.35675\tF1 0.45165\n",
      "Epoch: [8][90/278]\tLoss 0.65347\tAcc 0.74657\tPrecision 0.61584\tRecall 0.35686\tF1 0.45187\n",
      "Epoch: [8][100/278]\tLoss 0.65235\tAcc 0.74696\tPrecision 0.61652\tRecall 0.35737\tF1 0.45246\n",
      "Epoch: [8][110/278]\tLoss 0.65202\tAcc 0.74684\tPrecision 0.61622\tRecall 0.35821\tF1 0.45306\n",
      "Epoch: [8][120/278]\tLoss 0.65153\tAcc 0.74695\tPrecision 0.61646\tRecall 0.35883\tF1 0.45362\n",
      "Epoch: [8][130/278]\tLoss 0.65082\tAcc 0.74700\tPrecision 0.61592\tRecall 0.35902\tF1 0.45362\n",
      "Epoch: [8][140/278]\tLoss 0.65029\tAcc 0.74707\tPrecision 0.61621\tRecall 0.35988\tF1 0.45438\n",
      "Epoch: [8][150/278]\tLoss 0.64967\tAcc 0.74715\tPrecision 0.61632\tRecall 0.36065\tF1 0.45503\n",
      "Epoch: [8][160/278]\tLoss 0.64902\tAcc 0.74720\tPrecision 0.61627\tRecall 0.36128\tF1 0.45552\n",
      "Epoch: [8][170/278]\tLoss 0.64821\tAcc 0.74742\tPrecision 0.61659\tRecall 0.36180\tF1 0.45601\n",
      "Epoch: [8][180/278]\tLoss 0.64744\tAcc 0.74764\tPrecision 0.61730\tRecall 0.36233\tF1 0.45663\n",
      "Epoch: [8][190/278]\tLoss 0.64695\tAcc 0.74765\tPrecision 0.61732\tRecall 0.36329\tF1 0.45740\n",
      "Epoch: [8][200/278]\tLoss 0.64625\tAcc 0.74786\tPrecision 0.61746\tRecall 0.36381\tF1 0.45785\n",
      "Epoch: [8][210/278]\tLoss 0.64592\tAcc 0.74782\tPrecision 0.61747\tRecall 0.36523\tF1 0.45897\n",
      "Epoch: [8][220/278]\tLoss 0.64519\tAcc 0.74797\tPrecision 0.61813\tRecall 0.36604\tF1 0.45980\n",
      "Epoch: [8][230/278]\tLoss 0.64444\tAcc 0.74821\tPrecision 0.61846\tRecall 0.36696\tF1 0.46061\n",
      "Epoch: [8][240/278]\tLoss 0.64375\tAcc 0.74835\tPrecision 0.61825\tRecall 0.36716\tF1 0.46072\n",
      "Epoch: [8][250/278]\tLoss 0.64328\tAcc 0.74840\tPrecision 0.61839\tRecall 0.36782\tF1 0.46128\n",
      "Epoch: [8][260/278]\tLoss 0.64355\tAcc 0.74795\tPrecision 0.61654\tRecall 0.36823\tF1 0.46108\n",
      "Epoch: [8][270/278]\tLoss 0.64322\tAcc 0.74787\tPrecision 0.61609\tRecall 0.36920\tF1 0.46171\n",
      "Test: [0/21]\tLoss 0.69568\tAcc 0.66891\tPrecision 0.72078\tRecall 0.26278\tF1 0.38515\n",
      "Test: [10/21]\tLoss 0.67759\tAcc 0.68124\tPrecision 0.68859\tRecall 0.26278\tF1 0.38040\n",
      "Test: [20/21]\tLoss 0.68192\tAcc 0.67586\tPrecision 0.71888\tRecall 0.30135\tF1 0.42467\n",
      " * Acc 0.67586 F1 0.42467\n",
      "Epoch: [9][0/278]\tLoss 0.64277\tAcc 0.74790\tPrecision 0.61641\tRecall 0.36946\tF1 0.46201\n",
      "Epoch: [9][10/278]\tLoss 0.64236\tAcc 0.74796\tPrecision 0.61703\tRecall 0.36998\tF1 0.46259\n",
      "Epoch: [9][20/278]\tLoss 0.64169\tAcc 0.74804\tPrecision 0.61681\tRecall 0.37072\tF1 0.46310\n",
      "Epoch: [9][30/278]\tLoss 0.64090\tAcc 0.74823\tPrecision 0.61735\tRecall 0.37147\tF1 0.46384\n",
      "Epoch: [9][40/278]\tLoss 0.64009\tAcc 0.74844\tPrecision 0.61793\tRecall 0.37174\tF1 0.46421\n",
      "Epoch: [9][50/278]\tLoss 0.63951\tAcc 0.74858\tPrecision 0.61797\tRecall 0.37263\tF1 0.46492\n",
      "Epoch: [9][60/278]\tLoss 0.63920\tAcc 0.74851\tPrecision 0.61739\tRecall 0.37372\tF1 0.46560\n",
      "Epoch: [9][70/278]\tLoss 0.63885\tAcc 0.74843\tPrecision 0.61718\tRecall 0.37377\tF1 0.46558\n",
      "Epoch: [9][80/278]\tLoss 0.63870\tAcc 0.74823\tPrecision 0.61651\tRecall 0.37333\tF1 0.46505\n",
      "Epoch: [9][90/278]\tLoss 0.63850\tAcc 0.74789\tPrecision 0.61596\tRecall 0.37252\tF1 0.46427\n",
      "Epoch: [9][100/278]\tLoss 0.63841\tAcc 0.74762\tPrecision 0.61516\tRecall 0.37248\tF1 0.46400\n",
      "Epoch: [9][110/278]\tLoss 0.63779\tAcc 0.74774\tPrecision 0.61507\tRecall 0.37220\tF1 0.46376\n",
      "Epoch: [9][120/278]\tLoss 0.63736\tAcc 0.74782\tPrecision 0.61547\tRecall 0.37181\tF1 0.46357\n",
      "Epoch: [9][130/278]\tLoss 0.63683\tAcc 0.74791\tPrecision 0.61539\tRecall 0.37192\tF1 0.46364\n",
      "Epoch: [9][140/278]\tLoss 0.63619\tAcc 0.74816\tPrecision 0.61605\tRecall 0.37285\tF1 0.46455\n",
      "Epoch: [9][150/278]\tLoss 0.63554\tAcc 0.74825\tPrecision 0.61633\tRecall 0.37286\tF1 0.46464\n",
      "Epoch: [9][160/278]\tLoss 0.63501\tAcc 0.74839\tPrecision 0.61672\tRecall 0.37355\tF1 0.46528\n",
      "Epoch: [9][170/278]\tLoss 0.63430\tAcc 0.74865\tPrecision 0.61713\tRecall 0.37381\tF1 0.46559\n",
      "Epoch: [9][180/278]\tLoss 0.63363\tAcc 0.74894\tPrecision 0.61798\tRecall 0.37492\tF1 0.46669\n",
      "Epoch: [9][190/278]\tLoss 0.63313\tAcc 0.74909\tPrecision 0.61822\tRecall 0.37560\tF1 0.46729\n",
      "Epoch: [9][200/278]\tLoss 0.63269\tAcc 0.74928\tPrecision 0.61891\tRecall 0.37642\tF1 0.46813\n",
      "Epoch: [9][210/278]\tLoss 0.63198\tAcc 0.74952\tPrecision 0.61912\tRecall 0.37684\tF1 0.46851\n",
      "Epoch: [9][220/278]\tLoss 0.63143\tAcc 0.74980\tPrecision 0.61972\tRecall 0.37744\tF1 0.46915\n",
      "Epoch: [9][230/278]\tLoss 0.63098\tAcc 0.74983\tPrecision 0.61992\tRecall 0.37829\tF1 0.46986\n",
      "Epoch: [9][240/278]\tLoss 0.63036\tAcc 0.74995\tPrecision 0.62054\tRecall 0.37914\tF1 0.47069\n",
      "Epoch: [9][250/278]\tLoss 0.62983\tAcc 0.75006\tPrecision 0.62074\tRecall 0.37997\tF1 0.47139\n",
      "Epoch: [9][260/278]\tLoss 0.62908\tAcc 0.75032\tPrecision 0.62121\tRecall 0.38030\tF1 0.47178\n",
      "Epoch: [9][270/278]\tLoss 0.62821\tAcc 0.75060\tPrecision 0.62177\tRecall 0.38044\tF1 0.47205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/21]\tLoss 0.67845\tAcc 0.67758\tPrecision 0.71888\tRecall 0.30135\tF1 0.42467\n",
      "Test: [10/21]\tLoss 0.64559\tAcc 0.69386\tPrecision 0.71888\tRecall 0.30135\tF1 0.42467\n",
      "Test: [20/21]\tLoss 0.70768\tAcc 0.67429\tPrecision 0.72921\tRecall 0.28561\tF1 0.41045\n",
      " * Acc 0.67429 F1 0.41045\n",
      "Epoch: [10][0/278]\tLoss 0.62760\tAcc 0.75073\tPrecision 0.62180\tRecall 0.38081\tF1 0.47234\n",
      "Epoch: [10][10/278]\tLoss 0.62724\tAcc 0.75069\tPrecision 0.62148\tRecall 0.38083\tF1 0.47226\n",
      "Epoch: [10][20/278]\tLoss 0.62685\tAcc 0.75075\tPrecision 0.62122\tRecall 0.38173\tF1 0.47288\n",
      "Epoch: [10][30/278]\tLoss 0.62630\tAcc 0.75100\tPrecision 0.62187\tRecall 0.38288\tF1 0.47395\n",
      "Epoch: [10][40/278]\tLoss 0.62595\tAcc 0.75093\tPrecision 0.62163\tRecall 0.38314\tF1 0.47408\n",
      "Epoch: [10][50/278]\tLoss 0.62521\tAcc 0.75114\tPrecision 0.62201\tRecall 0.38338\tF1 0.47437\n",
      "Epoch: [10][60/278]\tLoss 0.62469\tAcc 0.75129\tPrecision 0.62230\tRecall 0.38388\tF1 0.47484\n",
      "Epoch: [10][70/278]\tLoss 0.62430\tAcc 0.75137\tPrecision 0.62237\tRecall 0.38443\tF1 0.47528\n",
      "Epoch: [10][80/278]\tLoss 0.62365\tAcc 0.75156\tPrecision 0.62263\tRecall 0.38468\tF1 0.47555\n",
      "Epoch: [10][90/278]\tLoss 0.62301\tAcc 0.75180\tPrecision 0.62336\tRecall 0.38522\tF1 0.47618\n",
      "Epoch: [10][100/278]\tLoss 0.62270\tAcc 0.75182\tPrecision 0.62349\tRecall 0.38591\tF1 0.47674\n",
      "Epoch: [10][110/278]\tLoss 0.62202\tAcc 0.75202\tPrecision 0.62382\tRecall 0.38620\tF1 0.47706\n",
      "Epoch: [10][120/278]\tLoss 0.62143\tAcc 0.75234\tPrecision 0.62440\tRecall 0.38654\tF1 0.47749\n",
      "Epoch: [10][130/278]\tLoss 0.62114\tAcc 0.75230\tPrecision 0.62390\tRecall 0.38702\tF1 0.47771\n",
      "Epoch: [10][140/278]\tLoss 0.62086\tAcc 0.75227\tPrecision 0.62370\tRecall 0.38751\tF1 0.47803\n",
      "Epoch: [10][150/278]\tLoss 0.62056\tAcc 0.75223\tPrecision 0.62365\tRecall 0.38803\tF1 0.47840\n",
      "Epoch: [10][160/278]\tLoss 0.62028\tAcc 0.75211\tPrecision 0.62342\tRecall 0.38851\tF1 0.47870\n",
      "Epoch: [10][170/278]\tLoss 0.61961\tAcc 0.75241\tPrecision 0.62397\tRecall 0.38896\tF1 0.47920\n",
      "Epoch: [10][180/278]\tLoss 0.61922\tAcc 0.75246\tPrecision 0.62389\tRecall 0.38919\tF1 0.47935\n",
      "Epoch: [10][190/278]\tLoss 0.61859\tAcc 0.75270\tPrecision 0.62466\tRecall 0.38990\tF1 0.48012\n",
      "Epoch: [10][200/278]\tLoss 0.61813\tAcc 0.75276\tPrecision 0.62479\tRecall 0.39035\tF1 0.48050\n",
      "Epoch: [10][210/278]\tLoss 0.61748\tAcc 0.75300\tPrecision 0.62522\tRecall 0.39091\tF1 0.48105\n",
      "Epoch: [10][220/278]\tLoss 0.61683\tAcc 0.75322\tPrecision 0.62560\tRecall 0.39134\tF1 0.48149\n",
      "Epoch: [10][230/278]\tLoss 0.61628\tAcc 0.75339\tPrecision 0.62612\tRecall 0.39216\tF1 0.48226\n",
      "Epoch: [10][240/278]\tLoss 0.61569\tAcc 0.75358\tPrecision 0.62624\tRecall 0.39264\tF1 0.48266\n",
      "Epoch: [10][250/278]\tLoss 0.61530\tAcc 0.75366\tPrecision 0.62642\tRecall 0.39298\tF1 0.48297\n",
      "Epoch: [10][260/278]\tLoss 0.61473\tAcc 0.75379\tPrecision 0.62682\tRecall 0.39342\tF1 0.48342\n",
      "Epoch: [10][270/278]\tLoss 0.61441\tAcc 0.75391\tPrecision 0.62699\tRecall 0.39405\tF1 0.48395\n",
      "Test: [0/21]\tLoss 0.70460\tAcc 0.67585\tPrecision 0.72921\tRecall 0.28561\tF1 0.41045\n",
      "Test: [10/21]\tLoss 0.67675\tAcc 0.69066\tPrecision 0.72921\tRecall 0.28561\tF1 0.41045\n",
      "Test: [20/21]\tLoss 0.70830\tAcc 0.67847\tPrecision 0.74599\tRecall 0.28822\tF1 0.41580\n",
      " * Acc 0.67847 F1 0.41580\n",
      "Epoch: [11][0/278]\tLoss 0.61430\tAcc 0.75379\tPrecision 0.62674\tRecall 0.39511\tF1 0.48467\n",
      "Epoch: [11][10/278]\tLoss 0.61379\tAcc 0.75386\tPrecision 0.62659\tRecall 0.39529\tF1 0.48476\n",
      "Epoch: [11][20/278]\tLoss 0.61327\tAcc 0.75402\tPrecision 0.62687\tRecall 0.39574\tF1 0.48519\n",
      "Epoch: [11][30/278]\tLoss 0.61305\tAcc 0.75403\tPrecision 0.62681\tRecall 0.39634\tF1 0.48562\n",
      "Epoch: [11][40/278]\tLoss 0.61239\tAcc 0.75425\tPrecision 0.62705\tRecall 0.39648\tF1 0.48579\n",
      "Epoch: [11][50/278]\tLoss 0.61196\tAcc 0.75440\tPrecision 0.62747\tRecall 0.39711\tF1 0.48640\n",
      "Epoch: [11][60/278]\tLoss 0.61159\tAcc 0.75450\tPrecision 0.62760\tRecall 0.39770\tF1 0.48688\n",
      "Epoch: [11][70/278]\tLoss 0.61098\tAcc 0.75463\tPrecision 0.62758\tRecall 0.39763\tF1 0.48682\n",
      "Epoch: [11][80/278]\tLoss 0.61058\tAcc 0.75474\tPrecision 0.62761\tRecall 0.39813\tF1 0.48720\n",
      "Epoch: [11][90/278]\tLoss 0.61001\tAcc 0.75488\tPrecision 0.62805\tRecall 0.39853\tF1 0.48763\n",
      "Epoch: [11][100/278]\tLoss 0.60965\tAcc 0.75503\tPrecision 0.62843\tRecall 0.39898\tF1 0.48808\n",
      "Epoch: [11][110/278]\tLoss 0.60940\tAcc 0.75499\tPrecision 0.62814\tRecall 0.39933\tF1 0.48826\n",
      "Epoch: [11][120/278]\tLoss 0.60895\tAcc 0.75505\tPrecision 0.62831\tRecall 0.39968\tF1 0.48857\n",
      "Epoch: [11][130/278]\tLoss 0.60850\tAcc 0.75521\tPrecision 0.62887\tRecall 0.40066\tF1 0.48948\n",
      "Epoch: [11][140/278]\tLoss 0.60814\tAcc 0.75531\tPrecision 0.62892\tRecall 0.40113\tF1 0.48984\n",
      "Epoch: [11][150/278]\tLoss 0.60821\tAcc 0.75508\tPrecision 0.62780\tRecall 0.40195\tF1 0.49011\n",
      "Epoch: [11][160/278]\tLoss 0.60826\tAcc 0.75509\tPrecision 0.62756\tRecall 0.40226\tF1 0.49026\n",
      "Epoch: [11][170/278]\tLoss 0.60792\tAcc 0.75515\tPrecision 0.62783\tRecall 0.40246\tF1 0.49050\n",
      "Epoch: [11][180/278]\tLoss 0.60755\tAcc 0.75518\tPrecision 0.62807\tRecall 0.40255\tF1 0.49064\n",
      "Epoch: [11][190/278]\tLoss 0.60713\tAcc 0.75532\tPrecision 0.62830\tRecall 0.40288\tF1 0.49095\n",
      "Epoch: [11][200/278]\tLoss 0.60666\tAcc 0.75545\tPrecision 0.62816\tRecall 0.40345\tF1 0.49133\n",
      "Epoch: [11][210/278]\tLoss 0.60630\tAcc 0.75548\tPrecision 0.62823\tRecall 0.40368\tF1 0.49153\n",
      "Epoch: [11][220/278]\tLoss 0.60590\tAcc 0.75557\tPrecision 0.62848\tRecall 0.40382\tF1 0.49170\n",
      "Epoch: [11][230/278]\tLoss 0.60561\tAcc 0.75563\tPrecision 0.62845\tRecall 0.40423\tF1 0.49200\n",
      "Epoch: [11][240/278]\tLoss 0.60528\tAcc 0.75563\tPrecision 0.62826\tRecall 0.40460\tF1 0.49221\n",
      "Epoch: [11][250/278]\tLoss 0.60477\tAcc 0.75585\tPrecision 0.62880\tRecall 0.40516\tF1 0.49280\n",
      "Epoch: [11][260/278]\tLoss 0.60428\tAcc 0.75599\tPrecision 0.62924\tRecall 0.40553\tF1 0.49320\n",
      "Epoch: [11][270/278]\tLoss 0.60397\tAcc 0.75599\tPrecision 0.62939\tRecall 0.40635\tF1 0.49386\n",
      "Test: [0/21]\tLoss 0.70578\tAcc 0.67987\tPrecision 0.74599\tRecall 0.28822\tF1 0.41580\n",
      "Test: [10/21]\tLoss 0.68427\tAcc 0.69232\tPrecision 0.74136\tRecall 0.28822\tF1 0.41508\n",
      "Test: [20/21]\tLoss 0.69673\tAcc 0.68521\tPrecision 0.76115\tRecall 0.30177\tF1 0.43219\n",
      " * Acc 0.68521 F1 0.43219\n",
      "Epoch: [12][0/278]\tLoss 0.60364\tAcc 0.75605\tPrecision 0.62945\tRecall 0.40674\tF1 0.49416\n",
      "Epoch: [12][10/278]\tLoss 0.60334\tAcc 0.75604\tPrecision 0.62962\tRecall 0.40735\tF1 0.49466\n",
      "Epoch: [12][20/278]\tLoss 0.60296\tAcc 0.75609\tPrecision 0.62983\tRecall 0.40784\tF1 0.49509\n",
      "Epoch: [12][30/278]\tLoss 0.60294\tAcc 0.75585\tPrecision 0.62904\tRecall 0.40814\tF1 0.49507\n",
      "Epoch: [12][40/278]\tLoss 0.60258\tAcc 0.75599\tPrecision 0.62939\tRecall 0.40876\tF1 0.49563\n",
      "Epoch: [12][50/278]\tLoss 0.60237\tAcc 0.75586\tPrecision 0.62905\tRecall 0.40878\tF1 0.49554\n",
      "Epoch: [12][60/278]\tLoss 0.60196\tAcc 0.75602\tPrecision 0.62939\tRecall 0.40894\tF1 0.49576\n",
      "Epoch: [12][70/278]\tLoss 0.60150\tAcc 0.75613\tPrecision 0.62993\tRecall 0.40922\tF1 0.49614\n",
      "Epoch: [12][80/278]\tLoss 0.60120\tAcc 0.75616\tPrecision 0.62990\tRecall 0.40973\tF1 0.49650\n",
      "Epoch: [12][90/278]\tLoss 0.60080\tAcc 0.75636\tPrecision 0.63019\tRecall 0.41034\tF1 0.49704\n",
      "Epoch: [12][100/278]\tLoss 0.60029\tAcc 0.75659\tPrecision 0.63080\tRecall 0.41090\tF1 0.49764\n",
      "Epoch: [12][110/278]\tLoss 0.59995\tAcc 0.75663\tPrecision 0.63094\tRecall 0.41134\tF1 0.49800\n",
      "Epoch: [12][120/278]\tLoss 0.59944\tAcc 0.75676\tPrecision 0.63103\tRecall 0.41137\tF1 0.49806\n",
      "Epoch: [12][130/278]\tLoss 0.59926\tAcc 0.75671\tPrecision 0.63057\tRecall 0.41164\tF1 0.49811\n",
      "Epoch: [12][140/278]\tLoss 0.59880\tAcc 0.75688\tPrecision 0.63101\tRecall 0.41187\tF1 0.49842\n",
      "Epoch: [12][150/278]\tLoss 0.59830\tAcc 0.75706\tPrecision 0.63139\tRecall 0.41271\tF1 0.49915\n",
      "Epoch: [12][160/278]\tLoss 0.59800\tAcc 0.75709\tPrecision 0.63129\tRecall 0.41323\tF1 0.49950\n",
      "Epoch: [12][170/278]\tLoss 0.59756\tAcc 0.75718\tPrecision 0.63131\tRecall 0.41348\tF1 0.49969\n",
      "Epoch: [12][180/278]\tLoss 0.59704\tAcc 0.75737\tPrecision 0.63165\tRecall 0.41367\tF1 0.49994\n",
      "Epoch: [12][190/278]\tLoss 0.59679\tAcc 0.75741\tPrecision 0.63173\tRecall 0.41448\tF1 0.50055\n",
      "Epoch: [12][200/278]\tLoss 0.59662\tAcc 0.75746\tPrecision 0.63163\tRecall 0.41454\tF1 0.50056\n",
      "Epoch: [12][210/278]\tLoss 0.59622\tAcc 0.75759\tPrecision 0.63171\tRecall 0.41453\tF1 0.50058\n",
      "Epoch: [12][220/278]\tLoss 0.59590\tAcc 0.75764\tPrecision 0.63169\tRecall 0.41447\tF1 0.50053\n",
      "Epoch: [12][230/278]\tLoss 0.59575\tAcc 0.75781\tPrecision 0.63181\tRecall 0.41475\tF1 0.50077\n",
      "Epoch: [12][240/278]\tLoss 0.59558\tAcc 0.75778\tPrecision 0.63161\tRecall 0.41489\tF1 0.50081\n",
      "Epoch: [12][250/278]\tLoss 0.59535\tAcc 0.75777\tPrecision 0.63153\tRecall 0.41524\tF1 0.50104\n",
      "Epoch: [12][260/278]\tLoss 0.59522\tAcc 0.75780\tPrecision 0.63156\tRecall 0.41592\tF1 0.50154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][270/278]\tLoss 0.59512\tAcc 0.75776\tPrecision 0.63135\tRecall 0.41607\tF1 0.50159\n",
      "Test: [0/21]\tLoss 0.69420\tAcc 0.68647\tPrecision 0.76115\tRecall 0.30177\tF1 0.43219\n",
      "Test: [10/21]\tLoss 0.66905\tAcc 0.69851\tPrecision 0.76115\tRecall 0.30177\tF1 0.43219\n",
      "Test: [20/21]\tLoss 0.71193\tAcc 0.67947\tPrecision 0.76209\tRecall 0.28001\tF1 0.40955\n",
      " * Acc 0.67947 F1 0.40955\n",
      "Epoch: [13][0/278]\tLoss 0.59489\tAcc 0.75781\tPrecision 0.63144\tRecall 0.41618\tF1 0.50169\n",
      "Epoch: [13][10/278]\tLoss 0.59494\tAcc 0.75776\tPrecision 0.63135\tRecall 0.41661\tF1 0.50198\n",
      "Epoch: [13][20/278]\tLoss 0.59458\tAcc 0.75788\tPrecision 0.63174\tRecall 0.41677\tF1 0.50222\n",
      "Epoch: [13][30/278]\tLoss 0.59422\tAcc 0.75803\tPrecision 0.63211\tRecall 0.41721\tF1 0.50266\n",
      "Epoch: [13][40/278]\tLoss 0.59395\tAcc 0.75804\tPrecision 0.63232\tRecall 0.41755\tF1 0.50296\n",
      "Epoch: [13][50/278]\tLoss 0.59359\tAcc 0.75811\tPrecision 0.63242\tRecall 0.41801\tF1 0.50333\n",
      "Epoch: [13][60/278]\tLoss 0.59311\tAcc 0.75828\tPrecision 0.63266\tRecall 0.41859\tF1 0.50383\n",
      "Epoch: [13][70/278]\tLoss 0.59291\tAcc 0.75838\tPrecision 0.63285\tRecall 0.41893\tF1 0.50413\n",
      "Epoch: [13][80/278]\tLoss 0.59260\tAcc 0.75842\tPrecision 0.63294\tRecall 0.41906\tF1 0.50426\n",
      "Epoch: [13][90/278]\tLoss 0.59216\tAcc 0.75860\tPrecision 0.63312\tRecall 0.41918\tF1 0.50441\n",
      "Epoch: [13][100/278]\tLoss 0.59181\tAcc 0.75867\tPrecision 0.63321\tRecall 0.41959\tF1 0.50473\n",
      "Epoch: [13][110/278]\tLoss 0.59143\tAcc 0.75882\tPrecision 0.63329\tRecall 0.41986\tF1 0.50495\n",
      "Epoch: [13][120/278]\tLoss 0.59087\tAcc 0.75904\tPrecision 0.63364\tRecall 0.42017\tF1 0.50528\n",
      "Epoch: [13][130/278]\tLoss 0.59049\tAcc 0.75919\tPrecision 0.63390\tRecall 0.42064\tF1 0.50570\n",
      "Epoch: [13][140/278]\tLoss 0.59024\tAcc 0.75930\tPrecision 0.63403\tRecall 0.42107\tF1 0.50606\n",
      "Epoch: [13][150/278]\tLoss 0.59007\tAcc 0.75930\tPrecision 0.63401\tRecall 0.42134\tF1 0.50625\n",
      "Epoch: [13][160/278]\tLoss 0.58978\tAcc 0.75945\tPrecision 0.63430\tRecall 0.42141\tF1 0.50639\n",
      "Epoch: [13][170/278]\tLoss 0.58946\tAcc 0.75949\tPrecision 0.63442\tRecall 0.42173\tF1 0.50666\n",
      "Epoch: [13][180/278]\tLoss 0.58907\tAcc 0.75953\tPrecision 0.63426\tRecall 0.42175\tF1 0.50663\n",
      "Epoch: [13][190/278]\tLoss 0.58875\tAcc 0.75959\tPrecision 0.63448\tRecall 0.42248\tF1 0.50722\n",
      "Epoch: [13][200/278]\tLoss 0.58834\tAcc 0.75976\tPrecision 0.63495\tRecall 0.42303\tF1 0.50777\n",
      "Epoch: [13][210/278]\tLoss 0.58805\tAcc 0.75986\tPrecision 0.63534\tRecall 0.42363\tF1 0.50832\n",
      "Epoch: [13][220/278]\tLoss 0.58760\tAcc 0.76005\tPrecision 0.63568\tRecall 0.42419\tF1 0.50883\n",
      "Epoch: [13][230/278]\tLoss 0.58722\tAcc 0.76014\tPrecision 0.63579\tRecall 0.42452\tF1 0.50911\n",
      "Epoch: [13][240/278]\tLoss 0.58683\tAcc 0.76026\tPrecision 0.63601\tRecall 0.42485\tF1 0.50941\n",
      "Epoch: [13][250/278]\tLoss 0.58636\tAcc 0.76046\tPrecision 0.63628\tRecall 0.42501\tF1 0.50962\n",
      "Epoch: [13][260/278]\tLoss 0.58598\tAcc 0.76056\tPrecision 0.63632\tRecall 0.42552\tF1 0.50999\n",
      "Epoch: [13][270/278]\tLoss 0.58561\tAcc 0.76066\tPrecision 0.63666\tRecall 0.42603\tF1 0.51047\n",
      "Test: [0/21]\tLoss 0.71011\tAcc 0.68053\tPrecision 0.76149\tRecall 0.28001\tF1 0.40946\n",
      "Test: [10/21]\tLoss 0.69223\tAcc 0.69056\tPrecision 0.75432\tRecall 0.28001\tF1 0.40841\n",
      "Test: [20/21]\tLoss 0.70028\tAcc 0.68657\tPrecision 0.77356\tRecall 0.29762\tF1 0.42986\n",
      " * Acc 0.68657 F1 0.42986\n",
      "Epoch: [14][0/278]\tLoss 0.58523\tAcc 0.76077\tPrecision 0.63701\tRecall 0.42647\tF1 0.51090\n",
      "Epoch: [14][10/278]\tLoss 0.58484\tAcc 0.76088\tPrecision 0.63727\tRecall 0.42723\tF1 0.51153\n",
      "Epoch: [14][20/278]\tLoss 0.58457\tAcc 0.76092\tPrecision 0.63723\tRecall 0.42759\tF1 0.51177\n",
      "Epoch: [14][30/278]\tLoss 0.58407\tAcc 0.76112\tPrecision 0.63763\tRecall 0.42817\tF1 0.51232\n",
      "Epoch: [14][40/278]\tLoss 0.58400\tAcc 0.76112\tPrecision 0.63774\tRecall 0.42856\tF1 0.51263\n",
      "Epoch: [14][50/278]\tLoss 0.58390\tAcc 0.76106\tPrecision 0.63742\tRecall 0.42876\tF1 0.51267\n",
      "Epoch: [14][60/278]\tLoss 0.58388\tAcc 0.76092\tPrecision 0.63679\tRecall 0.42912\tF1 0.51273\n",
      "Epoch: [14][70/278]\tLoss 0.58342\tAcc 0.76109\tPrecision 0.63700\tRecall 0.42918\tF1 0.51284\n",
      "Epoch: [14][80/278]\tLoss 0.58301\tAcc 0.76122\tPrecision 0.63730\tRecall 0.42934\tF1 0.51305\n",
      "Epoch: [14][90/278]\tLoss 0.58268\tAcc 0.76140\tPrecision 0.63792\tRecall 0.43000\tF1 0.51372\n",
      "Epoch: [14][100/278]\tLoss 0.58225\tAcc 0.76166\tPrecision 0.63864\tRecall 0.43066\tF1 0.51442\n",
      "Epoch: [14][110/278]\tLoss 0.58189\tAcc 0.76179\tPrecision 0.63889\tRecall 0.43100\tF1 0.51475\n",
      "Epoch: [14][120/278]\tLoss 0.58182\tAcc 0.76169\tPrecision 0.63867\tRecall 0.43166\tF1 0.51515\n",
      "Epoch: [14][130/278]\tLoss 0.58337\tAcc 0.76087\tPrecision 0.63570\tRecall 0.43219\tF1 0.51456\n",
      "Epoch: [14][140/278]\tLoss 0.58334\tAcc 0.76065\tPrecision 0.63570\tRecall 0.43099\tF1 0.51370\n",
      "Epoch: [14][150/278]\tLoss 0.58331\tAcc 0.76054\tPrecision 0.63572\tRecall 0.42998\tF1 0.51299\n",
      "Epoch: [14][160/278]\tLoss 0.58321\tAcc 0.76055\tPrecision 0.63572\tRecall 0.42932\tF1 0.51252\n",
      "Epoch: [14][170/278]\tLoss 0.58323\tAcc 0.76044\tPrecision 0.63572\tRecall 0.42865\tF1 0.51204\n",
      "Epoch: [14][180/278]\tLoss 0.58314\tAcc 0.76037\tPrecision 0.63569\tRecall 0.42771\tF1 0.51136\n",
      "Epoch: [14][190/278]\tLoss 0.58298\tAcc 0.76035\tPrecision 0.63574\tRecall 0.42691\tF1 0.51081\n",
      "Epoch: [14][200/278]\tLoss 0.58285\tAcc 0.76031\tPrecision 0.63578\tRecall 0.42615\tF1 0.51027\n",
      "Epoch: [14][210/278]\tLoss 0.58315\tAcc 0.75994\tPrecision 0.63459\tRecall 0.42640\tF1 0.51007\n",
      "Epoch: [14][220/278]\tLoss 0.58298\tAcc 0.75994\tPrecision 0.63453\tRecall 0.42574\tF1 0.50958\n",
      "Epoch: [14][230/278]\tLoss 0.58312\tAcc 0.75958\tPrecision 0.63366\tRecall 0.42575\tF1 0.50931\n",
      "Epoch: [14][240/278]\tLoss 0.58302\tAcc 0.75946\tPrecision 0.63355\tRecall 0.42491\tF1 0.50866\n",
      "Epoch: [14][250/278]\tLoss 0.58284\tAcc 0.75940\tPrecision 0.63348\tRecall 0.42409\tF1 0.50806\n",
      "Epoch: [14][260/278]\tLoss 0.58261\tAcc 0.75939\tPrecision 0.63362\tRecall 0.42348\tF1 0.50766\n",
      "Epoch: [14][270/278]\tLoss 0.58237\tAcc 0.75942\tPrecision 0.63372\tRecall 0.42350\tF1 0.50771\n",
      "Test: [0/21]\tLoss 0.69852\tAcc 0.68765\tPrecision 0.77356\tRecall 0.29762\tF1 0.42986\n",
      "Test: [10/21]\tLoss 0.68047\tAcc 0.69789\tPrecision 0.77301\tRecall 0.29762\tF1 0.42977\n",
      "Test: [20/21]\tLoss 0.69497\tAcc 0.68792\tPrecision 0.78140\tRecall 0.29697\tF1 0.43038\n",
      " * Acc 0.68792 F1 0.43038\n",
      "Epoch: [15][0/278]\tLoss 0.58219\tAcc 0.75950\tPrecision 0.63398\tRecall 0.42371\tF1 0.50795\n",
      "Epoch: [15][10/278]\tLoss 0.58188\tAcc 0.75958\tPrecision 0.63443\tRecall 0.42372\tF1 0.50810\n",
      "Epoch: [15][20/278]\tLoss 0.58171\tAcc 0.75958\tPrecision 0.63454\tRecall 0.42408\tF1 0.50839\n",
      "Epoch: [15][30/278]\tLoss 0.58148\tAcc 0.75965\tPrecision 0.63487\tRecall 0.42411\tF1 0.50852\n",
      "Epoch: [15][40/278]\tLoss 0.58129\tAcc 0.75969\tPrecision 0.63495\tRecall 0.42450\tF1 0.50883\n",
      "Epoch: [15][50/278]\tLoss 0.58105\tAcc 0.75971\tPrecision 0.63489\tRecall 0.42436\tF1 0.50870\n",
      "Epoch: [15][60/278]\tLoss 0.58078\tAcc 0.75985\tPrecision 0.63531\tRecall 0.42452\tF1 0.50895\n",
      "Epoch: [15][70/278]\tLoss 0.58055\tAcc 0.75982\tPrecision 0.63520\tRecall 0.42473\tF1 0.50907\n",
      "Epoch: [15][80/278]\tLoss 0.58057\tAcc 0.75964\tPrecision 0.63461\tRecall 0.42495\tF1 0.50904\n",
      "Epoch: [15][90/278]\tLoss 0.58049\tAcc 0.75954\tPrecision 0.63429\tRecall 0.42503\tF1 0.50899\n",
      "Epoch: [15][100/278]\tLoss 0.58037\tAcc 0.75949\tPrecision 0.63434\tRecall 0.42519\tF1 0.50912\n",
      "Epoch: [15][110/278]\tLoss 0.58007\tAcc 0.75961\tPrecision 0.63466\tRecall 0.42524\tF1 0.50926\n",
      "Epoch: [15][120/278]\tLoss 0.57980\tAcc 0.75965\tPrecision 0.63481\tRecall 0.42532\tF1 0.50937\n",
      "Epoch: [15][130/278]\tLoss 0.57957\tAcc 0.75964\tPrecision 0.63487\tRecall 0.42530\tF1 0.50937\n",
      "Epoch: [15][140/278]\tLoss 0.57926\tAcc 0.75977\tPrecision 0.63516\tRecall 0.42552\tF1 0.50963\n",
      "Epoch: [15][150/278]\tLoss 0.57891\tAcc 0.75988\tPrecision 0.63534\tRecall 0.42552\tF1 0.50968\n",
      "Epoch: [15][160/278]\tLoss 0.57869\tAcc 0.75991\tPrecision 0.63514\tRecall 0.42563\tF1 0.50970\n",
      "Epoch: [15][170/278]\tLoss 0.57836\tAcc 0.76007\tPrecision 0.63558\tRecall 0.42616\tF1 0.51022\n",
      "Epoch: [15][180/278]\tLoss 0.57806\tAcc 0.76019\tPrecision 0.63587\tRecall 0.42645\tF1 0.51052\n",
      "Epoch: [15][190/278]\tLoss 0.57779\tAcc 0.76026\tPrecision 0.63603\tRecall 0.42649\tF1 0.51060\n",
      "Epoch: [15][200/278]\tLoss 0.57746\tAcc 0.76041\tPrecision 0.63624\tRecall 0.42683\tF1 0.51091\n",
      "Epoch: [15][210/278]\tLoss 0.57739\tAcc 0.76038\tPrecision 0.63613\tRecall 0.42723\tF1 0.51116\n",
      "Epoch: [15][220/278]\tLoss 0.57704\tAcc 0.76051\tPrecision 0.63642\tRecall 0.42741\tF1 0.51138\n",
      "Epoch: [15][230/278]\tLoss 0.57668\tAcc 0.76068\tPrecision 0.63658\tRecall 0.42749\tF1 0.51149\n",
      "Epoch: [15][240/278]\tLoss 0.57652\tAcc 0.76069\tPrecision 0.63657\tRecall 0.42777\tF1 0.51169\n",
      "Epoch: [15][250/278]\tLoss 0.57628\tAcc 0.76080\tPrecision 0.63673\tRecall 0.42796\tF1 0.51188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][260/278]\tLoss 0.57603\tAcc 0.76087\tPrecision 0.63690\tRecall 0.42812\tF1 0.51205\n",
      "Epoch: [15][270/278]\tLoss 0.57567\tAcc 0.76104\tPrecision 0.63710\tRecall 0.42824\tF1 0.51220\n",
      "Test: [0/21]\tLoss 0.69344\tAcc 0.68892\tPrecision 0.78140\tRecall 0.29697\tF1 0.43038\n",
      "Test: [10/21]\tLoss 0.67638\tAcc 0.69846\tPrecision 0.78088\tRecall 0.29697\tF1 0.43030\n",
      "Test: [20/21]\tLoss 0.68911\tAcc 0.69135\tPrecision 0.79156\tRecall 0.30208\tF1 0.43729\n",
      " * Acc 0.69135 F1 0.43729\n",
      "Epoch: [16][0/278]\tLoss 0.57552\tAcc 0.76116\tPrecision 0.63739\tRecall 0.42860\tF1 0.51255\n",
      "Epoch: [16][10/278]\tLoss 0.57519\tAcc 0.76135\tPrecision 0.63776\tRecall 0.42887\tF1 0.51286\n",
      "Epoch: [16][20/278]\tLoss 0.57497\tAcc 0.76134\tPrecision 0.63763\tRecall 0.42898\tF1 0.51289\n",
      "Epoch: [16][30/278]\tLoss 0.57483\tAcc 0.76134\tPrecision 0.63749\tRecall 0.42908\tF1 0.51292\n",
      "Epoch: [16][40/278]\tLoss 0.57465\tAcc 0.76135\tPrecision 0.63746\tRecall 0.42937\tF1 0.51312\n",
      "Epoch: [16][50/278]\tLoss 0.57447\tAcc 0.76137\tPrecision 0.63754\tRecall 0.42929\tF1 0.51309\n",
      "Epoch: [16][60/278]\tLoss 0.57425\tAcc 0.76142\tPrecision 0.63759\tRecall 0.42935\tF1 0.51315\n",
      "Epoch: [16][70/278]\tLoss 0.57403\tAcc 0.76145\tPrecision 0.63761\tRecall 0.42946\tF1 0.51324\n",
      "Epoch: [16][80/278]\tLoss 0.57379\tAcc 0.76152\tPrecision 0.63775\tRecall 0.42978\tF1 0.51351\n",
      "Epoch: [16][90/278]\tLoss 0.57354\tAcc 0.76158\tPrecision 0.63787\tRecall 0.42997\tF1 0.51368\n",
      "Epoch: [16][100/278]\tLoss 0.57341\tAcc 0.76166\tPrecision 0.63797\tRecall 0.43039\tF1 0.51402\n",
      "Epoch: [16][110/278]\tLoss 0.57318\tAcc 0.76172\tPrecision 0.63816\tRecall 0.43061\tF1 0.51423\n",
      "Epoch: [16][120/278]\tLoss 0.57282\tAcc 0.76186\tPrecision 0.63847\tRecall 0.43082\tF1 0.51448\n",
      "Epoch: [16][130/278]\tLoss 0.57243\tAcc 0.76205\tPrecision 0.63888\tRecall 0.43118\tF1 0.51487\n",
      "Epoch: [16][140/278]\tLoss 0.57230\tAcc 0.76201\tPrecision 0.63875\tRecall 0.43155\tF1 0.51509\n",
      "Epoch: [16][150/278]\tLoss 0.57201\tAcc 0.76206\tPrecision 0.63883\tRecall 0.43166\tF1 0.51520\n"
     ]
    }
   ],
   "source": [
    "# %load train.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[1]:\n",
    "from t_cnn import tcnn\n",
    "\n",
    "model = tcnn(num_classes = 2,pretrained = True, model_root = '/home/krf/model/BALL/')\n",
    "\n",
    "import senet\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils import TransformImage\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "DATA_DIR = \"/home/krf/dataset/BALL/\"\n",
    "traindir = DATA_DIR + \"train\"\n",
    "valdir = DATA_DIR +\"val\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "BATCH_SIZE = 32\n",
    "WORKERS = 4\n",
    "START = 0\n",
    "EPOCHS = 400\n",
    "PRINT_FREQ = 10\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "#model =  senet.se_resnext50_32x4d(num_classes = 2)\n",
    "#通过随机变化来进行数据增强\n",
    "train_tf  = TransformImage(\n",
    "    model,\n",
    "    \n",
    "    random_crop=False,\n",
    "    random_hflip=True,\n",
    "    random_vflip=True,\n",
    "    random_rotate=True,\n",
    "    preserve_aspect_ratio=True\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.ImageFolder(traindir, transforms.Compose([\n",
    "# #         transforms.RandomSizedCrop(max(model.input_size)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ])),\n",
    "    datasets.ImageFolder(traindir,train_tf),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "\n",
    "val_tf = TransformImage(\n",
    "    model,\n",
    "    \n",
    "    preserve_aspect_ratio=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir,val_tf),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch,scheduler):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "#     end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "        input = input.cuda()\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input.float())\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        #print(input_var.type())\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        #print(output.data)\n",
    "\n",
    "\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "        meters = trainMeter.update(output,target,loss,input.size(0))\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss:.5f}\\t'\n",
    "                  'Acc {Acc:.5f}\\t'\n",
    "                  'Precision {P:.5f}\\t'\n",
    "                  'Recall {R:.5f}\\t'\n",
    "                  'F1 {F1:.5f}'.format(\n",
    "                   epoch,i, len(train_loader), loss=meters[4],\n",
    "                   Acc=meters[3],P=meters[0],R=meters[1],F1=meters[2]))\n",
    "            \n",
    "            step = epoch*len(train_loader) + i\n",
    "            \n",
    "            writer.add_scalar('TRAIN/Precision', meters[0], step)\n",
    "            writer.add_scalar('TRAIN/Recall', meters[1], step)\n",
    "            writer.add_scalar('TRAIN/F1', meters[2], step)\n",
    "            writer.add_scalar('TRAIN/Acc', meters[3], step)\n",
    "            writer.add_scalar('TRAIN/loss',meters[4], step)\n",
    "            \n",
    "    scheduler.step(meters[4])\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion,epoch):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "#     end = time.time()\n",
    "    meters = []\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "        input = input.cuda()\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        meters = valMeter.update(output,target,loss,input.size(0))\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Loss {loss:.5f}\\t'\n",
    "                  'Acc {Acc:.5f}\\t'\n",
    "                  'Precision {P:.5f}\\t'\n",
    "                  'Recall {R:.5f}\\t'\n",
    "                  'F1 {F1:.5f}'.format(\n",
    "                   i, len(val_loader), loss=meters[4],\n",
    "                   Acc=meters[3],P=meters[0],R=meters[1],F1=meters[2]))\n",
    "            \n",
    "            step = epoch * len(val_loader) + i\n",
    "            writer.add_scalar('VAL/Precision', meters[0], step)\n",
    "            writer.add_scalar('VAL/Recall', meters[1], step)\n",
    "            writer.add_scalar('VAL/F1', meters[2], step)\n",
    "            writer.add_scalar('VAL/Acc', meters[3], step)\n",
    "            writer.add_scalar('VAL/loss',meters[4], step)\n",
    "    print(' * Acc {Acc:.5f} F1 {F1:.5f}'\n",
    "          .format(Acc=meters[3],F1=meters[2]))\n",
    "    writer.add_scalar('VAL/EPOCH_F1', meters[2], epoch)\n",
    "    return meters[2]\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "class ModelMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.losses = AverageMeter()\n",
    "        self.top1 = AverageMeter()\n",
    "        self.TP = 0\n",
    "        self.TN = 0\n",
    "        self.FN = 0\n",
    "        self.FP = 0\n",
    "        self.P=0\n",
    "        self.R=0\n",
    "        self.F1=0\n",
    "        self.Acc=0\n",
    "\n",
    "    def update(self, output,target,loss, n=1):\n",
    "        _, pred = output.data.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "#         print(pred,target.data)\n",
    "        # TP    predict 和 label 同时为1\n",
    "        self.TP += ((pred == 1) & (target.data == 1)).cpu().numpy().sum()\n",
    "        # TN    predict 和 label 同时为0\n",
    "        self.TN += ((pred == 0) & (target.data == 0)).cpu().numpy().sum()\n",
    "        # FN    predict 0 label 1\n",
    "        self.FN += ((pred == 0) & (target.data == 1)).cpu().numpy().sum()\n",
    "        # FP    predict 1 label 0\n",
    "        self.FP += ((pred == 1) & (target.data == 0)).cpu().numpy().sum()\n",
    "#         print(self.TP,self.TN,self.FN,self.FP)\n",
    "        self.P = self.TP / (self.TP + self.FP)\n",
    "        self.R = self.TP / (self.TP + self.FN)\n",
    "        self.F1 = 2 * self.R * self.P / (self.R + self.P)\n",
    "        \n",
    "        self.Acc = (self.TP + self.TN) / (self.TP + self.TN + self.FP + self.FN)\n",
    "        \n",
    "        self.losses.update(loss.data[0],n)\n",
    "\n",
    "        return [self.P,self.R,self.F1,self.Acc,self.losses.avg]\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch):\n",
    "#     \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "#     lr = args.lr * (0.1 ** (epoch // 30))\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# 加载模型，解决命名和维度不匹配问题,解决多个gpu并行\n",
    "def load_state_keywise(model, model_path):\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "    START = checkpoint['epoch']\n",
    "    best_F1 = checkpoint['best_prec1']\n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    pretrained_dict = checkpoint['state_dict']#torch.load(model_path, map_location='cpu')\n",
    "    key = list(pretrained_dict.keys())[0]\n",
    "    # 1. filter out unnecessary keys\n",
    "    # 1.1 multi-GPU ->CPU\n",
    "    if (str(key).startswith('module.')):\n",
    "        pretrained_dict = {k[7:]: v for k, v in pretrained_dict.items() if\n",
    "                           k[7:] in model_dict and v.size() == model_dict[k[7:]].size()}\n",
    "    else:\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if\n",
    "                           k in model_dict and v.size() == model_dict[k].size()}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return START,best_F1\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-2,momentum = 0.9,weight_decay=1e-6)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True)\n",
    "\n",
    "# START,best_f1 = load_state_keywise(model,'checkpoint.pth.tar')\n",
    "# model = model.cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# TP = 0,TN = 0,FN = 0, FP = 0\n",
    "writer = SummaryWriter()\n",
    "best_f1 = 0\n",
    "trainMeter = ModelMeter()\n",
    "valMeter = ModelMeter()\n",
    "for epoch in range(START,EPOCHS):\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch, scheduler)\n",
    "    # evaluate on validation set\n",
    "    F1 = validate(val_loader, model, criterion,epoch)\n",
    "    \n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = F1 > best_f1\n",
    "    best_f1 = max(F1, best_f1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': \"T-CNN\",\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_f1,\n",
    "    }, is_best)\n",
    "# export scalar data to JSON for external processing\n",
    "writer.export_scalars_to_json(\"./test.json\")\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.model_zoo as model_zoo\n",
    "model_dict = model_zoo.load_url('https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth', '/home/krf/model/BALL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'odict_keys' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cb32f4b13958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpre_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'odict_keys' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "model = tcnn(2)\n",
    "pre_dict = model.state_dict()\n",
    "print(pre_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = ['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias']\n",
    "k2 = ['conv1.0.weight', 'conv1.0.bias', 'conv2.0.weight', 'conv2.0.bias', 'conv3.0.weight', 'conv3.0.bias', 'conv4.0.weight', 'conv4.0.bias', 'conv5.0.weight', 'conv5.0.bias', 'fc1.weight', 'fc1.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.3.weight', 'classifier.3.bias']\n",
    "for i in range(len(k1)):\n",
    "    pretrained_dict[k2[i]] = model_dict[k1[i]]\n",
    "\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
