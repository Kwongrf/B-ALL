{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senet\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils import TransformImage\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "DATA_DIR = \"/home/krf/dataset/BALL/\"\n",
    "traindir = DATA_DIR + \"train\"\n",
    "valdir = DATA_DIR +\"val\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "BATCH_SIZE = 2\n",
    "WORKERS = 4\n",
    "\n",
    "EPOCHS = 20\n",
    "PRINT_FREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  senet.se_resnext50_32x4d(num_classes = 2)\n",
    "#通过随机变化来进行数据增强\n",
    "train_tf  = TransformImage(\n",
    "    model,\n",
    "    scale=1,\n",
    "    random_crop=False,\n",
    "    random_hflip=True,\n",
    "    random_vflip=True,\n",
    "    random_rotate=True,\n",
    "    preserve_aspect_ratio=True\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.ImageFolder(traindir, transforms.Compose([\n",
    "# #         transforms.RandomSizedCrop(max(model.input_size)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ])),\n",
    "    datasets.ImageFolder(traindir,train_tf),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "\n",
    "val_tf = TransformImage(\n",
    "    model,\n",
    "    scale=1,\n",
    "    preserve_aspect_ratio=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir,val_tf),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch,scheduler):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "#     end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input.float())\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        #print(output.data)\n",
    "        # TP    predict 和 label 同时为1\n",
    "#         _, pred = output.topk(1, 1, True, True)\n",
    "#         pred = pred.t()\n",
    "#         print(pred,target.data)\n",
    "#         #correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "#         TP += ((pred == 1) & (target.data == 1)).cpu().numpy().sum()\n",
    "#         # TN    predict 和 label 同时为0\n",
    "#         TN += ((pred == 0) & (target.data == 0)).cpu().numpy().sum()\n",
    "#         # FN    predict 0 label 1\n",
    "#         FN += ((pred == 0) & (target.data == 1)).cpu().numpy().sum()\n",
    "#         # FP    predict 1 label 0\n",
    "#         FP += ((pred == 1) & (target.data == 0)).cpu().numpy().sum()\n",
    "#         print(TP,FP,TN,FN)\n",
    "        \n",
    "#         P = TP / (TP + FP)\n",
    "#         #print(P)\n",
    "#         R = TP / (TP + FN)\n",
    "#         F1 = 2 * R * P / (R + P)\n",
    "#         Acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        #print(F1)               \n",
    "#         # measure accuracy and record loss\n",
    "#         prec1= accuracy(output.data, target)\n",
    "#         losses.update(loss.data[0], input.size(0))\n",
    "#         top1.update(prec1[0], input.size(0))\n",
    "\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "        meters = trainMeter.update(output,target,loss,input.size(0))\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss:.5f}\\t'\n",
    "                  'Acc {Acc:.5f}\\t'\n",
    "                  'Precision {P:.5f}\\t'\n",
    "                  'Recall {R:.5f}\\t'\n",
    "                  'F1 {F1:.5f}'.format(\n",
    "                   epoch,i, len(train_loader), loss=meters[4],\n",
    "                   Acc=meters[3],P=meters[0],R=meters[1],F1=meters[2]))\n",
    "            \n",
    "            step = epoch*len(train_loader) + i\n",
    "           \n",
    "            writer.add_scalar('TRAIN/Precision', meters[0], step)\n",
    "            writer.add_scalar('TRAIN/Recall', meters[1], step)\n",
    "            writer.add_scalar('TRAIN/F1', meters[2], step)\n",
    "            writer.add_scalar('TRAIN/Acc', meters[3], step)\n",
    "            writer.add_scalar('TRAIN/loss',meters[4], step)\n",
    "            \n",
    "    scheduler.step(meters[4])\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion,epoch):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "#     end = time.time()\n",
    "    meters = []\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "        input = input.cuda()\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        meters = valMeter.update(output,target,loss,input.size(0))\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Loss {loss:.5f}\\t'\n",
    "                  'Acc {Acc:.5f}\\t'\n",
    "                  'Precision {P:.5f}\\t'\n",
    "                  'Recall {R:.5f}\\t'\n",
    "                  'F1 {F1:.5f}'.format(\n",
    "                   i, len(val_loader), loss=meters[4],\n",
    "                   Acc=meters[3],P=meters[0],R=meters[1],F1=meters[2]))\n",
    "            \n",
    "            step = epoch * len(val_loader) + i\n",
    "            writer.add_scalar('VAL/Precision', meters[0], step)\n",
    "            writer.add_scalar('VAL/Recall', meters[1], step)\n",
    "            writer.add_scalar('VAL/F1', meters[2], step)\n",
    "            writer.add_scalar('VAL/Acc', meters[3], step)\n",
    "            writer.add_scalar('VAL/loss',meters[4], step)\n",
    "    print(' * Acc {Acc:.5f} F1 {F1:.5f}'\n",
    "          .format(Acc=meters[3],F1=meters[2]))\n",
    "    writer.add_scalar('VAL/EPOCH_F1', meters[2], epoch)\n",
    "    return meters[2]\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "class ModelMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.losses = AverageMeter()\n",
    "        self.top1 = AverageMeter()\n",
    "        self.TP = 0\n",
    "        self.TN = 0\n",
    "        self.FN = 0\n",
    "        self.FP = 0\n",
    "        self.P=0\n",
    "        self.R=0\n",
    "        self.F1=0\n",
    "        self.Acc=0\n",
    "\n",
    "    def update(self, output,target,loss, n=1):\n",
    "        _, pred = output.data.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        #print(pred,target.data)\n",
    "        # TP    predict 和 label 同时为1\n",
    "        self.TP += ((pred == 1) & (target.data == 1)).cpu().numpy().sum()\n",
    "        # TN    predict 和 label 同时为0\n",
    "        self.TN += ((pred == 0) & (target.data == 0)).cpu().numpy().sum()\n",
    "        # FN    predict 0 label 1\n",
    "        self.FN += ((pred == 0) & (target.data == 1)).cpu().numpy().sum()\n",
    "        # FP    predict 1 label 0\n",
    "        self.FP += ((pred == 1) & (target.data == 0)).cpu().numpy().sum()\n",
    "        #print(self.TP,self.TN,self.FN,self.FP)\n",
    "        self.P = self.TP / (self.TP + self.FP)\n",
    "        self.R = self.TP / (self.TP + self.FN)\n",
    "        self.F1 = 2 * self.R * self.P / (self.R + self.P)\n",
    "        \n",
    "        self.Acc = (self.TP + self.TN) / (self.TP + self.TN + self.FP + self.FN)\n",
    "        \n",
    "        self.losses.update(loss.data[0],n)\n",
    "\n",
    "        return [self.P,self.R,self.F1,self.Acc,self.losses.avg]\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch):\n",
    "#     \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "#     lr = args.lr * (0.1 ** (epoch // 30))\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:151: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20][0/4443]\tLoss 0.10250\tAcc 1.00000\tPrecision 1.00000\tRecall 1.00000\tF1 1.00000\n",
      "Epoch: [20][10/4443]\tLoss 0.38075\tAcc 0.86364\tPrecision 0.83333\tRecall 0.71429\tF1 0.76923\n",
      "Epoch: [20][20/4443]\tLoss 0.24768\tAcc 0.92857\tPrecision 0.91667\tRecall 0.84615\tF1 0.88000\n",
      "Epoch: [20][30/4443]\tLoss 0.23911\tAcc 0.93548\tPrecision 0.94118\tRecall 0.84211\tF1 0.88889\n",
      "Epoch: [20][40/4443]\tLoss 0.20631\tAcc 0.92683\tPrecision 0.95238\tRecall 0.80000\tF1 0.86957\n",
      "Epoch: [20][50/4443]\tLoss 0.20505\tAcc 0.92157\tPrecision 0.92000\tRecall 0.79310\tF1 0.85185\n",
      "Epoch: [20][60/4443]\tLoss 0.18784\tAcc 0.91803\tPrecision 0.93103\tRecall 0.77143\tF1 0.84375\n",
      "Epoch: [20][70/4443]\tLoss 0.16964\tAcc 0.92958\tPrecision 0.94444\tRecall 0.80952\tF1 0.87179\n",
      "Epoch: [20][80/4443]\tLoss 0.16752\tAcc 0.92593\tPrecision 0.92857\tRecall 0.81250\tF1 0.86667\n",
      "Epoch: [20][90/4443]\tLoss 0.15810\tAcc 0.93407\tPrecision 0.94444\tRecall 0.85000\tF1 0.89474\n",
      "Epoch: [20][100/4443]\tLoss 0.15260\tAcc 0.93564\tPrecision 0.94915\tRecall 0.84848\tF1 0.89600\n",
      "Epoch: [20][110/4443]\tLoss 0.15450\tAcc 0.93694\tPrecision 0.93548\tRecall 0.85294\tF1 0.89231\n",
      "Epoch: [20][120/4443]\tLoss 0.14289\tAcc 0.94215\tPrecision 0.94118\tRecall 0.86486\tF1 0.90141\n",
      "Epoch: [20][130/4443]\tLoss 0.15051\tAcc 0.94275\tPrecision 0.94595\tRecall 0.86420\tF1 0.90323\n",
      "Epoch: [20][140/4443]\tLoss 0.14070\tAcc 0.94681\tPrecision 0.95062\tRecall 0.87500\tF1 0.91124\n",
      "Epoch: [20][150/4443]\tLoss 0.15744\tAcc 0.94040\tPrecision 0.94118\tRecall 0.86022\tF1 0.89888\n",
      "Epoch: [20][160/4443]\tLoss 0.15860\tAcc 0.93789\tPrecision 0.94505\tRecall 0.85149\tF1 0.89583\n",
      "Epoch: [20][170/4443]\tLoss 0.15322\tAcc 0.94152\tPrecision 0.94792\tRecall 0.85849\tF1 0.90099\n",
      "Epoch: [20][180/4443]\tLoss 0.15213\tAcc 0.94199\tPrecision 0.94118\tRecall 0.86486\tF1 0.90141\n",
      "Epoch: [20][190/4443]\tLoss 0.16969\tAcc 0.93455\tPrecision 0.91818\tRecall 0.86325\tF1 0.88987\n",
      "Epoch: [20][200/4443]\tLoss 0.16985\tAcc 0.93532\tPrecision 0.91525\tRecall 0.87097\tF1 0.89256\n",
      "Epoch: [20][210/4443]\tLoss 0.16427\tAcc 0.93602\tPrecision 0.92000\tRecall 0.87121\tF1 0.89494\n",
      "Epoch: [20][220/4443]\tLoss 0.17216\tAcc 0.93439\tPrecision 0.92308\tRecall 0.86331\tF1 0.89219\n",
      "Epoch: [20][230/4443]\tLoss 0.17547\tAcc 0.93290\tPrecision 0.91729\tRecall 0.85915\tF1 0.88727\n",
      "Epoch: [20][240/4443]\tLoss 0.17187\tAcc 0.93361\tPrecision 0.91176\tRecall 0.86111\tF1 0.88571\n",
      "Epoch: [20][250/4443]\tLoss 0.16526\tAcc 0.93625\tPrecision 0.91304\tRecall 0.86301\tF1 0.88732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-167:\n",
      "Process Process-168:\n",
      "Process Process-165:\n",
      "Process Process-166:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6b04c086f538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTART\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b4590dc7d08b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, scheduler)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#         # measure elapsed time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/krf/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 加载模型，解决命名和维度不匹配问题,解决多个gpu并行\n",
    "def load_state_keywise(model, model_path):\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "    START = checkpoint['epoch']\n",
    "    best_F1 = checkpoint['best_prec1']\n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    pretrained_dict = checkpoint['state_dict']#torch.load(model_path, map_location='cpu')\n",
    "    key = list(pretrained_dict.keys())[0]\n",
    "    # 1. filter out unnecessary keys\n",
    "    # 1.1 multi-GPU ->CPU\n",
    "    if (str(key).startswith('module.')):\n",
    "        pretrained_dict = {k[7:]: v for k, v in pretrained_dict.items() if\n",
    "                           k[7:] in model_dict and v.size() == model_dict[k[7:]].size()}\n",
    "    else:\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if\n",
    "                           k in model_dict and v.size() == model_dict[k].size()}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return START,best_F1\n",
    "\n",
    "\n",
    "EPOCHS = 40\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True)\n",
    "\n",
    "START,best_f1 = load_state_keywise(model,'checkpoint.pth.tar')\n",
    "#model = model.cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# TP = 0,TN = 0,FN = 0, FP = 0\n",
    "writer = SummaryWriter()\n",
    "# best_f1 = 0\n",
    "trainMeter = ModelMeter()\n",
    "valMeter = ModelMeter()\n",
    "for epoch in range(START,EPOCHS):\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch, scheduler)\n",
    "    # evaluate on validation set\n",
    "    F1 = validate(val_loader, model, criterion,epoch)\n",
    "    \n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = F1 > best_f1\n",
    "    best_f1 = max(F1, best_f1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': \"SE_ResNeXt50\",\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_f1,\n",
    "    }, is_best)\n",
    "# export scalar data to JSON for external processing\n",
    "writer.export_scalars_to_json(\"./test.json\")\n",
    "writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
